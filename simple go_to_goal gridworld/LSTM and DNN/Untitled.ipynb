{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b05e71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Omega-automaton states (including the trap state): 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<csrl.oaa.oaa at 0x14d53bb82e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state: 0\n",
      "Transition function: [\n",
      "  {(): 0, ('a',): 0, ('b',): 0, ('a', 'b'): 0}\n",
      "]\n",
      "Acceptance: [\n",
      "  {(): [None], ('a',): [None], ('b',): [True], ('a', 'b'): [None]}\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### import manually defined automata\n",
    "%matplotlib inline\n",
    "from csrl.mdp import GridMDP\n",
    "#from csrl.oa import OmegaAutomaton\n",
    "from csrl.oaa import oaa\n",
    "from csrl import ControlSynthesis\n",
    "import numpy as np \n",
    "\n",
    "oa=oaa()\n",
    "\n",
    "print('Number of Omega-automaton states (including the trap state):',oa.shape[1])\n",
    "display(oa)\n",
    "\n",
    "print('Initial state:',oa.q0)\n",
    "print('Transition function: ['),print(*['  '+str(t) for t in oa.delta],sep=',\\n'),print(']')\n",
    "print('Acceptance: ['),print(*['  '+str(t) for t in oa.acc],sep=',\\n'),print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65dd063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JUNCHA~1\\AppData\\Local\\Temp/ipykernel_21356/4015061931.py:29: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ],dtype=np.object)\n"
     ]
    }
   ],
   "source": [
    "# MDP Description\n",
    "shape = (10,10)\n",
    "# E: Empty, T: Trap, B: Obstacle\n",
    "structure = np.array([\n",
    "['E',  'E',  'E',  'E',  'B',  'B',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'B',  'B',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['B',  'B',  'E',  'E',  'B',  'B',  'E',  'E',  'B',  'B'],\n",
    "['B',  'B',  'E',  'E',  'B',  'B',  'E',  'E',  'B',  'B'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'B',  'B',  'E',  'E',  'E',  'E'],\n",
    "['E',  'E',  'E',  'E',  'B',  'B',  'E',  'E',  'E',  'E']\n",
    "])\n",
    "\n",
    "# Labels of the states\n",
    "label = np.array([\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       ('b',),       ('b',)],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       ('b',),       ('b',)],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[(),       (),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[('a',),       ('a',),       (),       (),       (),       (),       (),       (),       (),       ()],\n",
    "[('a',),       ('a',),       (),       (),       (),       (),       (),       (),       (),       ()]\n",
    "],dtype=np.object)\n",
    "# Colors of the labels\n",
    "lcmap={\n",
    "    ('a',):'lightgreen',\n",
    "    ('b',):'lightgreen'\n",
    "}\n",
    "grid_mdp = GridMDP(shape=shape,structure=structure,label=label,lcmap=lcmap,figsize=5)  # Use figsize=4 for smaller figures\n",
    "#grid_mdp.plot()\n",
    "\n",
    "# Construct the product MDP\n",
    "csrl = ControlSynthesis(grid_mdp,oa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6820a7e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10., 10.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10., 10.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csrl.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1396d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])],\n",
       "         [list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3]), list([0, 1, 2, 3]), list([0, 1, 2, 3]),\n",
       "          list([0, 1, 2, 3])]]]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csrl.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee8ea50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START state: (0, 0, 8, 0)\n",
      "episode: 0/1000, steps: 500, e: 1.0\n",
      "accumulated_rewards_per_episode: 180.0\n",
      "START state: (0, 0, 8, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1/1000, steps: 500, e: 0.99\n",
      "accumulated_rewards_per_episode: 60.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 2/1000, steps: 500, e: 0.98\n",
      "accumulated_rewards_per_episode: 750.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 3/1000, steps: 500, e: 0.96\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 4/1000, steps: 500, e: 0.95\n",
      "accumulated_rewards_per_episode: 60.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 5/1000, steps: 500, e: 0.94\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 6/1000, steps: 500, e: 0.93\n",
      "accumulated_rewards_per_episode: 160.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 7/1000, steps: 500, e: 0.92\n",
      "accumulated_rewards_per_episode: 140.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 8/1000, steps: 500, e: 0.91\n",
      "accumulated_rewards_per_episode: 230.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 9/1000, steps: 500, e: 0.9\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 10/1000, steps: 500, e: 0.89\n",
      "accumulated_rewards_per_episode: 90.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 11/1000, steps: 500, e: 0.88\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 12/1000, steps: 500, e: 0.87\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 13/1000, steps: 500, e: 0.86\n",
      "accumulated_rewards_per_episode: 630.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 14/1000, steps: 500, e: 0.85\n",
      "accumulated_rewards_per_episode: 970.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 15/1000, steps: 500, e: 0.84\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 16/1000, steps: 500, e: 0.83\n",
      "accumulated_rewards_per_episode: 920.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 17/1000, steps: 500, e: 0.82\n",
      "accumulated_rewards_per_episode: 120.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 18/1000, steps: 500, e: 0.81\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 19/1000, steps: 500, e: 0.8\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 20/1000, steps: 500, e: 0.79\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 21/1000, steps: 500, e: 0.78\n",
      "accumulated_rewards_per_episode: 1320.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 22/1000, steps: 500, e: 0.77\n",
      "accumulated_rewards_per_episode: 320.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 23/1000, steps: 500, e: 0.76\n",
      "accumulated_rewards_per_episode: 2750.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 24/1000, steps: 500, e: 0.75\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 25/1000, steps: 500, e: 0.74\n",
      "accumulated_rewards_per_episode: 370.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 26/1000, steps: 500, e: 0.73\n",
      "accumulated_rewards_per_episode: 2300.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 27/1000, steps: 500, e: 0.72\n",
      "accumulated_rewards_per_episode: 1000.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 28/1000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 1410.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 29/1000, steps: 500, e: 0.71\n",
      "accumulated_rewards_per_episode: 1420.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 30/1000, steps: 500, e: 0.7\n",
      "accumulated_rewards_per_episode: 2770.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 31/1000, steps: 500, e: 0.69\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 32/1000, steps: 500, e: 0.68\n",
      "accumulated_rewards_per_episode: 2190.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 33/1000, steps: 500, e: 0.67\n",
      "accumulated_rewards_per_episode: 1920.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 34/1000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 2550.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 35/1000, steps: 500, e: 0.66\n",
      "accumulated_rewards_per_episode: 2410.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 36/1000, steps: 500, e: 0.65\n",
      "accumulated_rewards_per_episode: 190.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 37/1000, steps: 500, e: 0.64\n",
      "accumulated_rewards_per_episode: 3180.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 38/1000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 39/1000, steps: 500, e: 0.63\n",
      "accumulated_rewards_per_episode: 2690.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 40/1000, steps: 500, e: 0.62\n",
      "accumulated_rewards_per_episode: 1730.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 41/1000, steps: 500, e: 0.61\n",
      "accumulated_rewards_per_episode: 2920.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 42/1000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 2360.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 43/1000, steps: 500, e: 0.6\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 44/1000, steps: 500, e: 0.59\n",
      "accumulated_rewards_per_episode: 300.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 45/1000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 2920.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 46/1000, steps: 500, e: 0.58\n",
      "accumulated_rewards_per_episode: 3690.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 47/1000, steps: 500, e: 0.57\n",
      "accumulated_rewards_per_episode: 2900.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 48/1000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 49/1000, steps: 500, e: 0.56\n",
      "accumulated_rewards_per_episode: 2280.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 50/1000, steps: 500, e: 0.55\n",
      "accumulated_rewards_per_episode: 3490.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 51/1000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 2050.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 52/1000, steps: 500, e: 0.54\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 53/1000, steps: 500, e: 0.53\n",
      "accumulated_rewards_per_episode: 3300.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 54/1000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 3010.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 55/1000, steps: 500, e: 0.52\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 56/1000, steps: 500, e: 0.51\n",
      "accumulated_rewards_per_episode: 3670.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 57/1000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 3840.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 58/1000, steps: 500, e: 0.5\n",
      "accumulated_rewards_per_episode: 3400.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 59/1000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 2340.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 60/1000, steps: 500, e: 0.49\n",
      "accumulated_rewards_per_episode: 3410.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 61/1000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 1110.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 62/1000, steps: 500, e: 0.48\n",
      "accumulated_rewards_per_episode: 3460.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 63/1000, steps: 500, e: 0.47\n",
      "accumulated_rewards_per_episode: 2210.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 64/1000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 3820.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 65/1000, steps: 500, e: 0.46\n",
      "accumulated_rewards_per_episode: 3440.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 66/1000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 3580.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 67/1000, steps: 500, e: 0.45\n",
      "accumulated_rewards_per_episode: 2600.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 68/1000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 3100.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 69/1000, steps: 500, e: 0.44\n",
      "accumulated_rewards_per_episode: 3450.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 70/1000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 3260.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 71/1000, steps: 500, e: 0.43\n",
      "accumulated_rewards_per_episode: 4010.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 72/1000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 4030.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 73/1000, steps: 500, e: 0.42\n",
      "accumulated_rewards_per_episode: 3730.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 74/1000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 3450.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 75/1000, steps: 500, e: 0.41\n",
      "accumulated_rewards_per_episode: 3680.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 76/1000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 3700.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 77/1000, steps: 500, e: 0.4\n",
      "accumulated_rewards_per_episode: 4160.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 78/1000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 3560.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 79/1000, steps: 500, e: 0.39\n",
      "accumulated_rewards_per_episode: 3540.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 80/1000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 3590.0\n",
      "START state: (0, 0, 8, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 81/1000, steps: 500, e: 0.38\n",
      "accumulated_rewards_per_episode: 3740.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 82/1000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 4100.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 83/1000, steps: 500, e: 0.37\n",
      "accumulated_rewards_per_episode: 3100.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 84/1000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 4090.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 85/1000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 3360.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 86/1000, steps: 500, e: 0.36\n",
      "accumulated_rewards_per_episode: 3100.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 87/1000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 3820.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 88/1000, steps: 500, e: 0.35\n",
      "accumulated_rewards_per_episode: 3300.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 89/1000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 90/1000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 3690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 91/1000, steps: 500, e: 0.34\n",
      "accumulated_rewards_per_episode: 3640.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 92/1000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 3270.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 93/1000, steps: 500, e: 0.33\n",
      "accumulated_rewards_per_episode: 3310.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 94/1000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 3580.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 95/1000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 4180.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 96/1000, steps: 500, e: 0.32\n",
      "accumulated_rewards_per_episode: 4440.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 97/1000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 3770.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 98/1000, steps: 500, e: 0.31\n",
      "accumulated_rewards_per_episode: 1040.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 99/1000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 4130.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 100/1000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 4020.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 101/1000, steps: 500, e: 0.3\n",
      "accumulated_rewards_per_episode: 2070.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 102/1000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 0.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 103/1000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 2220.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 104/1000, steps: 500, e: 0.29\n",
      "accumulated_rewards_per_episode: 4180.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 105/1000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 3860.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 106/1000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 4410.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 107/1000, steps: 500, e: 0.28\n",
      "accumulated_rewards_per_episode: 4000.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 108/1000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 3800.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 109/1000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 2360.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 110/1000, steps: 500, e: 0.27\n",
      "accumulated_rewards_per_episode: 4400.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 111/1000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 4250.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 112/1000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 3770.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 113/1000, steps: 500, e: 0.26\n",
      "accumulated_rewards_per_episode: 4180.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 114/1000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 3890.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 115/1000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 4280.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 116/1000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 4280.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 117/1000, steps: 500, e: 0.25\n",
      "accumulated_rewards_per_episode: 3990.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 118/1000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 4410.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 119/1000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 3480.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 120/1000, steps: 500, e: 0.24\n",
      "accumulated_rewards_per_episode: 3410.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 121/1000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 4090.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 122/1000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 4270.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 123/1000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 4500.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 124/1000, steps: 500, e: 0.23\n",
      "accumulated_rewards_per_episode: 3940.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 125/1000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 4470.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 126/1000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 4420.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 127/1000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 4410.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 128/1000, steps: 500, e: 0.22\n",
      "accumulated_rewards_per_episode: 4500.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 129/1000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 4490.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 130/1000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 4350.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 131/1000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 4100.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 132/1000, steps: 500, e: 0.21\n",
      "accumulated_rewards_per_episode: 4450.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 133/1000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 3920.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 134/1000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 4420.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 135/1000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 4240.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 136/1000, steps: 500, e: 0.2\n",
      "accumulated_rewards_per_episode: 4280.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 137/1000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 4310.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 138/1000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 4360.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 139/1000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 4400.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 140/1000, steps: 500, e: 0.19\n",
      "accumulated_rewards_per_episode: 4100.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 141/1000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 3150.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 142/1000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 4450.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 143/1000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 144/1000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 4250.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 145/1000, steps: 500, e: 0.18\n",
      "accumulated_rewards_per_episode: 4380.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 146/1000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 4390.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 147/1000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 4500.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 148/1000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 4540.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 149/1000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 150/1000, steps: 500, e: 0.17\n",
      "accumulated_rewards_per_episode: 3990.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 151/1000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 4270.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 152/1000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 4490.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 153/1000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 4420.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 154/1000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 155/1000, steps: 500, e: 0.16\n",
      "accumulated_rewards_per_episode: 4500.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 156/1000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 4310.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 157/1000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 4250.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 158/1000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 4450.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 159/1000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 4320.0\n",
      "START state: (0, 0, 9, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 160/1000, steps: 500, e: 0.15\n",
      "accumulated_rewards_per_episode: 4520.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 161/1000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 162/1000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 4300.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 163/1000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 4370.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 164/1000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 4320.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 165/1000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 4510.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 166/1000, steps: 500, e: 0.14\n",
      "accumulated_rewards_per_episode: 4270.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 167/1000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 4140.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 168/1000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 169/1000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 170/1000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 3930.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 171/1000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 4410.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 172/1000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 4200.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 173/1000, steps: 500, e: 0.13\n",
      "accumulated_rewards_per_episode: 4550.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 174/1000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 4260.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 175/1000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 176/1000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 4440.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 177/1000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 4360.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 178/1000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 4500.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 179/1000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 180/1000, steps: 500, e: 0.12\n",
      "accumulated_rewards_per_episode: 4400.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 181/1000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 3880.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 182/1000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 4560.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 183/1000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 4130.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 184/1000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 4250.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 185/1000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 3690.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 186/1000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 4210.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 187/1000, steps: 500, e: 0.11\n",
      "accumulated_rewards_per_episode: 4430.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 188/1000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 4270.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 189/1000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 4440.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 190/1000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 191/1000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 4200.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 192/1000, steps: 500, e: 0.1\n",
      "accumulated_rewards_per_episode: 4540.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 193/1000, steps: 500, e: 0.099\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 194/1000, steps: 500, e: 0.097\n",
      "accumulated_rewards_per_episode: 4080.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 195/1000, steps: 500, e: 0.096\n",
      "accumulated_rewards_per_episode: 4360.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 196/1000, steps: 500, e: 0.095\n",
      "accumulated_rewards_per_episode: 4170.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 197/1000, steps: 500, e: 0.094\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 198/1000, steps: 500, e: 0.093\n",
      "accumulated_rewards_per_episode: 4370.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 199/1000, steps: 500, e: 0.092\n",
      "accumulated_rewards_per_episode: 4510.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 200/1000, steps: 500, e: 0.091\n",
      "accumulated_rewards_per_episode: 4460.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 201/1000, steps: 500, e: 0.09\n",
      "accumulated_rewards_per_episode: 4550.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 202/1000, steps: 500, e: 0.089\n",
      "accumulated_rewards_per_episode: 4560.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 203/1000, steps: 500, e: 0.088\n",
      "accumulated_rewards_per_episode: 4560.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 204/1000, steps: 500, e: 0.086\n",
      "accumulated_rewards_per_episode: 4480.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 205/1000, steps: 500, e: 0.085\n",
      "accumulated_rewards_per_episode: 4150.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 206/1000, steps: 500, e: 0.084\n",
      "accumulated_rewards_per_episode: 4480.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 207/1000, steps: 500, e: 0.083\n",
      "accumulated_rewards_per_episode: 3960.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 208/1000, steps: 500, e: 0.082\n",
      "accumulated_rewards_per_episode: 4560.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 209/1000, steps: 500, e: 0.081\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 210/1000, steps: 500, e: 0.08\n",
      "accumulated_rewards_per_episode: 4240.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 211/1000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 212/1000, steps: 500, e: 0.079\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 213/1000, steps: 500, e: 0.078\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 214/1000, steps: 500, e: 0.077\n",
      "accumulated_rewards_per_episode: 4540.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 215/1000, steps: 500, e: 0.076\n",
      "accumulated_rewards_per_episode: 4550.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 216/1000, steps: 500, e: 0.075\n",
      "accumulated_rewards_per_episode: 4510.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 217/1000, steps: 500, e: 0.074\n",
      "accumulated_rewards_per_episode: 4480.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 218/1000, steps: 500, e: 0.073\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 219/1000, steps: 500, e: 0.072\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 220/1000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 4320.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 221/1000, steps: 500, e: 0.071\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 222/1000, steps: 500, e: 0.07\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 223/1000, steps: 500, e: 0.069\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 224/1000, steps: 500, e: 0.068\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 225/1000, steps: 500, e: 0.067\n",
      "accumulated_rewards_per_episode: 4510.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 226/1000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 227/1000, steps: 500, e: 0.066\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 228/1000, steps: 500, e: 0.065\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 229/1000, steps: 500, e: 0.064\n",
      "accumulated_rewards_per_episode: 4470.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 230/1000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 231/1000, steps: 500, e: 0.063\n",
      "accumulated_rewards_per_episode: 4520.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 232/1000, steps: 500, e: 0.062\n",
      "accumulated_rewards_per_episode: 4480.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 233/1000, steps: 500, e: 0.061\n",
      "accumulated_rewards_per_episode: 4430.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 234/1000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 4550.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 235/1000, steps: 500, e: 0.06\n",
      "accumulated_rewards_per_episode: 4540.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 236/1000, steps: 500, e: 0.059\n",
      "accumulated_rewards_per_episode: 4520.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 237/1000, steps: 500, e: 0.058\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 8, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 238/1000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 4510.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 239/1000, steps: 500, e: 0.057\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 240/1000, steps: 500, e: 0.056\n",
      "accumulated_rewards_per_episode: 4260.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 241/1000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 4540.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 242/1000, steps: 500, e: 0.055\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 243/1000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 4130.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 244/1000, steps: 500, e: 0.054\n",
      "accumulated_rewards_per_episode: 4440.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 245/1000, steps: 500, e: 0.053\n",
      "accumulated_rewards_per_episode: 4520.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 246/1000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 4410.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 247/1000, steps: 500, e: 0.052\n",
      "accumulated_rewards_per_episode: 4520.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 248/1000, steps: 500, e: 0.051\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 249/1000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 250/1000, steps: 500, e: 0.05\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 251/1000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 252/1000, steps: 500, e: 0.049\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 253/1000, steps: 500, e: 0.048\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 254/1000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 3890.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 255/1000, steps: 500, e: 0.047\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 256/1000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 4450.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 257/1000, steps: 500, e: 0.046\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 258/1000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 4480.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 259/1000, steps: 500, e: 0.045\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 260/1000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 4420.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 261/1000, steps: 500, e: 0.044\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 262/1000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 263/1000, steps: 500, e: 0.043\n",
      "accumulated_rewards_per_episode: 4350.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 264/1000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 265/1000, steps: 500, e: 0.042\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 266/1000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 267/1000, steps: 500, e: 0.041\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 268/1000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 269/1000, steps: 500, e: 0.04\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 270/1000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 4440.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 271/1000, steps: 500, e: 0.039\n",
      "accumulated_rewards_per_episode: 4340.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 272/1000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 273/1000, steps: 500, e: 0.038\n",
      "accumulated_rewards_per_episode: 4500.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 274/1000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 275/1000, steps: 500, e: 0.037\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 276/1000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 277/1000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 278/1000, steps: 500, e: 0.036\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 279/1000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 280/1000, steps: 500, e: 0.035\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 281/1000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 4130.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 282/1000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 283/1000, steps: 500, e: 0.034\n",
      "accumulated_rewards_per_episode: 4440.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 284/1000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 285/1000, steps: 500, e: 0.033\n",
      "accumulated_rewards_per_episode: 4790.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 286/1000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 287/1000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 288/1000, steps: 500, e: 0.032\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 289/1000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 290/1000, steps: 500, e: 0.031\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 291/1000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 292/1000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 293/1000, steps: 500, e: 0.03\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 294/1000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 295/1000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 296/1000, steps: 500, e: 0.029\n",
      "accumulated_rewards_per_episode: 4550.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 297/1000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 298/1000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 299/1000, steps: 500, e: 0.028\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 300/1000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 301/1000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 302/1000, steps: 500, e: 0.027\n",
      "accumulated_rewards_per_episode: 4430.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 303/1000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 304/1000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 4480.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 305/1000, steps: 500, e: 0.026\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 306/1000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 307/1000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 4390.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 308/1000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 309/1000, steps: 500, e: 0.025\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 310/1000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 311/1000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 312/1000, steps: 500, e: 0.024\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 313/1000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 314/1000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 315/1000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 316/1000, steps: 500, e: 0.023\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 317/1000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 318/1000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 319/1000, steps: 500, e: 0.022\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 320/1000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 321/1000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 322/1000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 323/1000, steps: 500, e: 0.021\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 324/1000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 325/1000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 326/1000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 327/1000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 328/1000, steps: 500, e: 0.02\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 329/1000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 330/1000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 331/1000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 332/1000, steps: 500, e: 0.019\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 333/1000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 334/1000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 335/1000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 336/1000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 337/1000, steps: 500, e: 0.018\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 338/1000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 339/1000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 4510.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 340/1000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 4480.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 341/1000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 342/1000, steps: 500, e: 0.017\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 343/1000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 4560.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 344/1000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 345/1000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 346/1000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 347/1000, steps: 500, e: 0.016\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 348/1000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 4440.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 349/1000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 350/1000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 351/1000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 4420.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 352/1000, steps: 500, e: 0.015\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 353/1000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 354/1000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 355/1000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 356/1000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 4540.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 357/1000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 358/1000, steps: 500, e: 0.014\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 359/1000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 360/1000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 361/1000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 362/1000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 363/1000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 364/1000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 365/1000, steps: 500, e: 0.013\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 366/1000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 367/1000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 368/1000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 369/1000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 4310.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 370/1000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 371/1000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 372/1000, steps: 500, e: 0.012\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 373/1000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 4550.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 374/1000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 4500.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 375/1000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 376/1000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 4480.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 377/1000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 378/1000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 379/1000, steps: 500, e: 0.011\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 380/1000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 381/1000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 382/1000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 4810.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 383/1000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 384/1000, steps: 500, e: 0.01\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 385/1000, steps: 500, e: 0.0099\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 386/1000, steps: 500, e: 0.0097\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 387/1000, steps: 500, e: 0.0096\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 388/1000, steps: 500, e: 0.0095\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 389/1000, steps: 500, e: 0.0094\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 390/1000, steps: 500, e: 0.0093\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 391/1000, steps: 500, e: 0.0092\n",
      "accumulated_rewards_per_episode: 4520.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 392/1000, steps: 500, e: 0.0091\n",
      "accumulated_rewards_per_episode: 4520.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 393/1000, steps: 500, e: 0.009\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 394/1000, steps: 500, e: 0.0088\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 395/1000, steps: 500, e: 0.0087\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 396/1000, steps: 500, e: 0.0086\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 397/1000, steps: 500, e: 0.0085\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 398/1000, steps: 500, e: 0.0084\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 399/1000, steps: 500, e: 0.0083\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 400/1000, steps: 500, e: 0.0082\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 401/1000, steps: 500, e: 0.0081\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 402/1000, steps: 500, e: 0.008\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 403/1000, steps: 500, e: 0.0079\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 404/1000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 405/1000, steps: 500, e: 0.0078\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 406/1000, steps: 500, e: 0.0077\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 407/1000, steps: 500, e: 0.0076\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 408/1000, steps: 500, e: 0.0075\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 409/1000, steps: 500, e: 0.0074\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 410/1000, steps: 500, e: 0.0073\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 411/1000, steps: 500, e: 0.0072\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 412/1000, steps: 500, e: 0.0071\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 413/1000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 414/1000, steps: 500, e: 0.007\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 415/1000, steps: 500, e: 0.0069\n",
      "accumulated_rewards_per_episode: 4500.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 416/1000, steps: 500, e: 0.0068\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 417/1000, steps: 500, e: 0.0067\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 418/1000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 419/1000, steps: 500, e: 0.0066\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 420/1000, steps: 500, e: 0.0065\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 421/1000, steps: 500, e: 0.0064\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 422/1000, steps: 500, e: 0.0063\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 423/1000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 424/1000, steps: 500, e: 0.0062\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 425/1000, steps: 500, e: 0.0061\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 426/1000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 427/1000, steps: 500, e: 0.006\n",
      "accumulated_rewards_per_episode: 4170.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 428/1000, steps: 500, e: 0.0059\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 429/1000, steps: 500, e: 0.0058\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 430/1000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 431/1000, steps: 500, e: 0.0057\n",
      "accumulated_rewards_per_episode: 4550.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 432/1000, steps: 500, e: 0.0056\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 433/1000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 434/1000, steps: 500, e: 0.0055\n",
      "accumulated_rewards_per_episode: 4560.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 435/1000, steps: 500, e: 0.0054\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 436/1000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 437/1000, steps: 500, e: 0.0053\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 438/1000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 439/1000, steps: 500, e: 0.0052\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 440/1000, steps: 500, e: 0.0051\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 441/1000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 442/1000, steps: 500, e: 0.005\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 443/1000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 444/1000, steps: 500, e: 0.0049\n",
      "accumulated_rewards_per_episode: 4500.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 445/1000, steps: 500, e: 0.0048\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 446/1000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 447/1000, steps: 500, e: 0.0047\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 448/1000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 4520.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 449/1000, steps: 500, e: 0.0046\n",
      "accumulated_rewards_per_episode: 4000.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 450/1000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 451/1000, steps: 500, e: 0.0045\n",
      "accumulated_rewards_per_episode: 4250.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 452/1000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 453/1000, steps: 500, e: 0.0044\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 454/1000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 4550.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 455/1000, steps: 500, e: 0.0043\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 456/1000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 457/1000, steps: 500, e: 0.0042\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 458/1000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 459/1000, steps: 500, e: 0.0041\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 460/1000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 461/1000, steps: 500, e: 0.004\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 462/1000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 463/1000, steps: 500, e: 0.0039\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 464/1000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 465/1000, steps: 500, e: 0.0038\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 466/1000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 467/1000, steps: 500, e: 0.0037\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 468/1000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 469/1000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 470/1000, steps: 500, e: 0.0036\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 471/1000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 472/1000, steps: 500, e: 0.0035\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 473/1000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 474/1000, steps: 500, e: 0.0034\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 475/1000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 476/1000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 477/1000, steps: 500, e: 0.0033\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 478/1000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 479/1000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 4450.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 480/1000, steps: 500, e: 0.0032\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 481/1000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 482/1000, steps: 500, e: 0.0031\n",
      "accumulated_rewards_per_episode: 4420.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 483/1000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 484/1000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 485/1000, steps: 500, e: 0.003\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 486/1000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 4510.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 487/1000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 488/1000, steps: 500, e: 0.0029\n",
      "accumulated_rewards_per_episode: 4480.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 489/1000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 490/1000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 491/1000, steps: 500, e: 0.0028\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 492/1000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 493/1000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 494/1000, steps: 500, e: 0.0027\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 495/1000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 496/1000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 497/1000, steps: 500, e: 0.0026\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 498/1000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 499/1000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 500/1000, steps: 500, e: 0.0025\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 501/1000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 502/1000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 503/1000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 504/1000, steps: 500, e: 0.0024\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 505/1000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 506/1000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 507/1000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 508/1000, steps: 500, e: 0.0023\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 509/1000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 4520.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 510/1000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 511/1000, steps: 500, e: 0.0022\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 512/1000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 513/1000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 514/1000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 4790.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 515/1000, steps: 500, e: 0.0021\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 516/1000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 517/1000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 518/1000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 519/1000, steps: 500, e: 0.002\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 520/1000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 521/1000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 522/1000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 523/1000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 524/1000, steps: 500, e: 0.0019\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 525/1000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 526/1000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 527/1000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 528/1000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 529/1000, steps: 500, e: 0.0018\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 530/1000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 531/1000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 532/1000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 533/1000, steps: 500, e: 0.0017\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 534/1000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 535/1000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 536/1000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 537/1000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 538/1000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 539/1000, steps: 500, e: 0.0016\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 540/1000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 541/1000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 542/1000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 543/1000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 544/1000, steps: 500, e: 0.0015\n",
      "accumulated_rewards_per_episode: 4790.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 545/1000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 546/1000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 547/1000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 8, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 548/1000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 549/1000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 550/1000, steps: 500, e: 0.0014\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 551/1000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 552/1000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 4790.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 553/1000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 554/1000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 555/1000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 556/1000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 557/1000, steps: 500, e: 0.0013\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 558/1000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 559/1000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 560/1000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 561/1000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 562/1000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 563/1000, steps: 500, e: 0.0012\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 564/1000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 565/1000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 566/1000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 567/1000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 568/1000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 569/1000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 570/1000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 571/1000, steps: 500, e: 0.0011\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 572/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 573/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4480.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 574/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 575/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 576/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 577/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 578/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4550.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 579/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 580/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 581/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 582/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 583/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 584/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 585/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 586/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 587/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 588/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 589/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 590/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 591/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 592/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 593/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 594/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 595/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 596/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 597/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 598/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 599/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 600/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 601/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 602/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 603/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 604/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 605/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 606/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 607/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 608/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 609/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 610/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 611/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 612/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 613/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 614/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 615/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 616/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 617/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 618/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 619/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 620/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 621/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4350.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 622/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 623/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 624/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 625/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 626/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 627/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 628/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 629/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 630/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 631/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 632/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 633/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 634/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 635/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 636/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 637/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 638/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 639/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 640/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 641/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 642/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 643/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 644/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 645/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 646/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 647/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 648/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4790.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 649/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 650/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 651/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 652/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 653/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 654/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 655/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 656/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4520.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 657/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 658/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 659/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 660/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 661/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 662/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 663/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4480.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 664/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 665/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 666/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 667/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 668/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 669/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 670/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 671/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 672/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 673/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 674/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4560.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 675/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4540.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 676/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 677/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4560.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 678/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 679/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 680/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 681/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 682/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 683/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 684/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 685/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 686/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 687/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 688/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 689/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 690/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 691/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 692/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 693/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 694/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 695/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 696/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 697/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 698/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 699/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 700/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 701/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 702/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 703/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 9, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 704/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 705/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 706/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 707/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 708/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 709/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 710/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 711/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 712/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 713/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 714/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 715/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 716/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4320.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 717/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4810.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 718/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 719/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 720/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 721/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 722/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 723/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 724/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 725/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 726/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 727/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4810.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 728/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 729/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 730/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 731/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 732/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 733/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 734/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 735/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 736/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 737/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 738/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 739/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 740/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 741/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 742/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 743/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 744/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 745/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 746/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 747/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 748/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 749/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 750/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 751/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 752/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 753/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 754/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 755/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 756/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 757/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 758/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 759/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 760/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 761/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 762/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 763/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 764/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 765/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 766/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 767/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 768/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 769/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 770/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4810.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 771/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 772/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 773/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4790.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 774/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 775/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 776/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 777/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 778/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 779/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4820.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 780/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 781/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 782/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 783/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 784/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 785/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 786/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 787/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 788/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 789/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 790/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 791/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 792/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 793/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4790.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 794/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 795/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 796/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 797/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 798/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 799/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 800/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 801/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4550.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 802/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 803/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4790.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 804/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 805/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 806/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 807/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 808/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4810.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 809/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 810/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 811/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 812/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 813/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 814/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 815/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 816/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 817/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4820.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 818/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 819/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 820/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 821/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 822/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 823/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 824/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 825/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 826/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 827/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4510.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 828/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 829/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 830/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 831/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 832/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 833/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 834/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 835/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 836/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 837/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 838/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 839/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 840/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 841/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 842/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 843/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 844/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 845/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 846/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 847/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 848/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 849/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 850/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 851/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 852/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 853/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 854/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 855/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 856/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4790.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 857/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 858/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 859/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 860/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 861/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 862/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 863/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 864/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 865/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 866/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 867/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 868/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 869/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 870/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 871/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 872/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 873/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 874/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 875/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 876/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 877/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 878/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 879/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 880/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 881/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 882/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 883/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 884/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 885/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 886/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4560.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 887/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 888/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 889/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 890/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 891/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 892/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 893/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 894/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 895/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 896/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 897/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4470.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 898/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 899/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 900/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 901/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 902/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 903/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 904/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 905/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 906/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 907/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4620.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 908/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 909/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4540.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 910/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 911/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4560.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 912/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 913/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 914/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 915/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 916/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 917/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 918/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 919/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 920/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 921/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 922/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4780.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 923/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 924/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 925/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 926/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 927/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 928/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 929/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 930/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 931/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 932/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 933/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4730.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 934/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 935/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 936/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4650.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 937/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 938/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 939/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 940/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 941/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 942/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 943/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 944/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 945/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 946/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 947/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 948/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 949/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4790.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 950/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 951/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 952/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 953/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4540.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 954/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 955/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4550.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 956/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4560.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 957/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 958/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 959/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4500.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 960/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4700.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 961/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 962/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4770.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 963/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 964/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4640.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 965/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 966/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 967/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 968/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 969/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4630.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 970/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4600.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 971/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 972/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 973/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4760.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 974/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 975/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4530.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 976/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 977/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4790.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 978/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 979/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 980/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 981/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 982/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4790.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 983/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4720.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 984/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 985/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 986/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4690.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 987/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4570.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 988/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4610.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 989/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4590.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 990/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 991/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4800.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 992/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4580.0\n",
      "START state: (0, 0, 8, 1)\n",
      "episode: 993/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4740.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 994/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4540.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 995/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4680.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 996/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4660.0\n",
      "START state: (0, 0, 9, 1)\n",
      "episode: 997/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4750.0\n",
      "START state: (0, 0, 9, 0)\n",
      "episode: 998/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4670.0\n",
      "START state: (0, 0, 8, 0)\n",
      "episode: 999/1000, steps: 500, e: 0.001\n",
      "accumulated_rewards_per_episode: 4710.0\n",
      "Finished in 1186.2461 second(s)\n"
     ]
    }
   ],
   "source": [
    " t2, epsilon, average_accumulated_rewards = csrl.train_DRQN(EPISODES=1000, num_steps=500, batch_size=32, weights_update=50, state_sequence_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b66d29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig, ax1 = plt.subplots() \n",
    "\n",
    "ax1.set_xlabel('Episode(s)', fontsize=12) \n",
    "ax1.set_ylabel('Exploration Rate', fontsize=12, color = 'red') \n",
    "ax1.plot(t2, epsilon, color = 'red') \n",
    "ax1.tick_params(axis ='y', labelcolor = 'red') \n",
    "# Adding Twin Axes\n",
    "ax2 = ax1.twinx() \n",
    "ax2.set_ylabel('Accumulated Rewards / 10 Episodes', fontsize=12, color = 'blue') \n",
    "ax2.plot(t2, average_accumulated_rewards, color = 'blue') \n",
    "ax2.tick_params(axis ='y', labelcolor = 'blue') \n",
    "# Show plot\n",
    "#plt.title('The Accumulated Rewards of 10 by 10 Grid-world Simulation (label uncertainty Pl = 1.0)', fontsize=14)\n",
    "plt.grid()\n",
    "plt.rcParams['figure.figsize'] = [8, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f0d5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "np.array(t2).tofile('episodes_X axis.csv', sep = ',')\n",
    "np.array(average_accumulated_rewards).tofile('rewards_go_to_goal_RNN.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4682db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results\n",
    "import pandas as pd\n",
    "t2_read = np.loadtxt('episodes_X axis.csv', delimiter=',')\n",
    "average_read = np.loadtxt('rewards_go_to_goal_RNN.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0168793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "RGB = 256\n",
    "# blue\n",
    "royalblue = (65/RGB,105/RGB,225/RGB)\n",
    "dodgerblue = (30/RGB,144/RGB,255/RGB)\n",
    "# green\n",
    "green = (0/RGB,128/RGB,0/RGB)\n",
    "# purple\n",
    "darkorchid = (104/RGB,34/RGB,139/RGB)\n",
    "# red & pink\n",
    "coral = (205/RGB,91/RGB,69/RGB)\n",
    "red = (139/RGB,0/RGB,0/RGB)\n",
    "pink = (252/RGB,20/RGB,201/RGB)\n",
    "orange = (255/RGB,128/RGB,0/RGB)\n",
    "\n",
    "def cumsum_sma(array, period):\n",
    "    ret = np.cumsum(array, dtype=float)\n",
    "    ret[period:] = ret[period:] - ret[:-period]\n",
    "    return ret[period - 1:] / period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83455afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = cumsum_sma(t2,30)\n",
    "averaged = cumsum_sma(average_accumulated_rewards,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d324f5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAGtCAYAAACrySipAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAACj+ElEQVR4nOy9d5gb1dn+f09RW2m71703TLGxDdiAsQ0kYCCQlxAg2HkN+ZFQAwQIxA6BwDcQCCH4DZCXBNIA03khgQCmBmyqIcbGYIyNK+5eb5dWZcr5/THSqEujXUlztPt8rsuXV1PP6JY09zznOc8RGGMMBEEQBEEQBLeIdjeAIAiCIAiCyA0ZNoIgCIIgCM4hw0YQBEEQBME5ZNgIgiAIgiA4hwwbQRAEQRAE58h2N6DU6LoOTaOBsARBEARB8I/DIWVc3ucNm6YxtLd3l/QcVVVOdHdHSnoOonBIF/4gTfiEdOEP0oRPyqFLU1N1xuVlN2xnnnkmqquNxgwfPhyXXnopFi9eDEEQMGHCBNx8880QRRFPP/00nnzySciyjMsuuwwnnHACQqEQrr/+erS0tMDr9eLOO+9EQ0NDuS8hDa/XRV8sDiFd+IM04RPShT9IEz6xU5eyGrZwOAwAWLp0qbns0ksvxdVXX42ZM2fil7/8Jd58801MnToVS5cuxbPPPotwOIwFCxZg1qxZeOKJJzBx4kRceeWVeOmll3D//ffjxhtvLOclEARBEARBlJ2yDjr48ssvEQwGceGFF+L888/HmjVrsG7dOsyYMQMAMGfOHLz//vtYu3Ytpk2bBqfTierqaowcORJffvklVq1ahdmzZ5vbfvDBB+VsPkEQBEEQhC2UNcLmdrvxwx/+EOeccw62bduGiy66CIwxCIIAAPB6vejq6oLf7ze7TWPL/X5/0vLYtvkQRSGpP7itLQAAqK/3mssCgTC6uyNoaPBCkgwPqyga2tu74fO54PE4zW1bWvyQZRG1tVVJ+wPJ/c7hsIrOziBqajxwueJvc3NzF9xuB6qr3eayjo5uqKqOxkafuSwYjMDvD6OurspMQNQ0Ha2tAVRVOeH1ukp6TV1dIYRCSkVfk98fSmp/X7imStcpHE5ua1+4pr6gE2D8fvWla+oLOjU1Vfe5a+oLOsmyWJZrSkUo51yikUgEuq7D7TbeuLPPPhvr1q3D+vXrAQBvvPEG3n//fcyaNQvvvPMObrnlFgDAj3/8Y1x66aV44IEHcPHFF2PKlCno6urC/Pnz8eKLL+Y8Z+wNKyWyLEJV9ZKegygc0oU/SBM+IV34gzThk3Loks20lbVL9P/+7//wm9/8BgCwb98++P1+zJo1CytXrgQArFixAkceeSSmTJmCVatWIRwOo6urC5s3b8bEiRMxffp0LF++3Nz2iCOOKGfzs5Losgl+IF34gzThE9KFP0gTPrFTl7JH2H7+859j9+7dEAQB1113Herr63HTTTdBURSMHTsWt912GyRJwtNPP42nnnoKjDFccsklmDdvHoLBIBYtWoTm5mY4HA7cfffdaGpqynnOckTYmpqq0dycv3uWKC+kC3+QJnxCuvAHacIn5dAlW4StrIbNDsiw9V9IF/4gTfiEdOEP0oRP7DRsNDVVEYgNOiD4gnThD9KET0gX/iBN+MROXSjCRhAEQRAEwQkUYSshsWHxBF+QLvxBmvAJ6cIfpAmf2KkLGbYiEKu5QvAF6cIfpAmfkC78QZrwiZ260CeCIAiCIAiCc8iwFQFF0exuApEB0oU/SBM+IV34gzThEzt1oUEHBEEQBFEONAUQZSA6HWOv0DXjOALFXfoaNOighPh8rvwbEWWHdCkjSjeEUFvezUgTPuk3uqghCMGW5GWaAqG7ufjnUrohhFrjr3UNzh1vQGrbYGn3JE2YDiGwN2m9Y8cbcHz9RjFaShSAnd8VMmxFIHFSV4IfuNdFCUBq+QLoA0Fu567lcOz9MO92vdJEVyEdWGtEKWxA7Poaon8XRP9uiF07bWlDMZFaN5iGwi0p/H0W1RCkA58DrHjzNjr2fQzHvo+SrlNuXg3H/v9ACLUmvQdix1YI3ft7fC7jO7EyvkA3Prdi13ZL+yd+V6T2zXA0r05qj8B0CIyvblMxsAdiZ5brY8x4fxV/eRtlASHcnv5ZUwLRZcnfCTvvK2TYCKKECJGurDccef9qSF3b4dz+ivHD0KPjd/J1k80DC3cZXTmFooYgtW2E5N8FqXNb0dsFphtaZUPXILesg3xgLeQDn0Ju+Sy+TosASjztQmpZB8e2V5KWWUXo3gfntmWAZhTnFIItxutCj6UpgBrMsT4CqXNL3FDs/hhS13ZADRTc5nxIrRvg2P5q/g1TNJBb1kHy74AQPGDpPEKkM/9GsfdEC8X3U4xrlvd+FH0PjPdabvsSjv2rsh9LC5s65cKx820jqhc1V0KW3wPHtlcgtW1MXrbjLUgHPot/HtTSpfc4tr8KqdVa9C8bcvMayK1fZF6pBiB1bYe8f43xWteA6HsPJQDoqvFb2QNDJ+9bBXlP/gfGVMSOrXBuWwax62tI/h1JZtOx7z+Q/DtK8p3oKWTYCKJUMB2O3e9C3vtx3k0l/w5AUyB2bLFswIRwBxy734PYuSVtndi5HVBDyQuVbohdOywduyQwBmx7G46db+XcTOjeByHcnrTMufMt42YKFDXiIvp3Q4h0QWrbAMfud7MaIyGcpbuX6XDueNPYN4rU9TUEMDh3Lc9+YjUIsevrtMVSdFns+kW/oZeY7fxp7WEQO7bAsWsFnDvfzrqZoKSYU/M9jedWZdKhJ0idWwyTkudzLbV+abyPptFkSf8LwQPxLkZdg9i+yTT/Qqg1+l3YZnyHskVhZbexfaKZjeaACSjswce5499w7vh35pUJDyWCGoQQ6YCgq9kPxhgEMEgdm5MWC1oIkn8nIDqix81xjF4iMB1Sht8SIPpZyJfykEdf8/qj+Xty82o4d60wvkO7VkDe/wmktg1w7non98NGBsTg/qzfEbFjq/FQlQGp3TDIQswQJ5pFsw1FyDcsEmTYikBLC38hXqKIuqhBOHYuL/hHJPajLYZb82xo4Nj5FuS2DRC79+bfmOlme8RQq/Fa1wBdhWPn25Bbv4Dc/Gny8fd9DLnlc8tdilLrBogpN5A0Um8gucyUrqKrKwhBV+I3NF1L/qHXVTj2fwLHng+M10rAiDAlHyj9PLoGec/KpCiL6N8NeV+OCAkA+cCncOx+14zaCbrxwy4d+DzJUAkZfvDlPSshBI3cp5xdU1FdEq/TsfcjyC3rAE2BvG8VRP8uAACL3pjl/atTzHX0pqEGIe9ZmW7GozqI/l2Q2zaY15H0PjEGee9KCN3NydFExtDZHnvNzEhHkg4JiO1fQdq/Go5d7xjRkOg5xM5tkFrX53gfcn/uYqZYyBK1cuz72IwISm0bILd/BbHra8h7VkKM5qBJHVsht22A1JI5Ys0kI/9ISHz/0pL2WVbzIbVugNj+Vd4ocWokTFC6Ie95P+EULOm7I+/7KHkdgJb96b8bQob3sKCoWOr3LUbi5zvl+wjA+CzkS3lIuGaxY0t6r4Fp2CTjv6j5jpkkMdRifi7Fnj4opOgihFoht30J+cBnkHe/Hz9n9z7I+z4GBNl4HT2fkBh5jT0oxL7b0fbbeb8nw1YEZJneRh7JqIumWO5iiSF17YCgdkNq25C72yyNxJtlBiOTMlIs9sNg5RyOXe/A0bzaPLa87z9wfv0axMCeePQg9cc9+mMk5ArxM93Mk5E6t0BO7KJR/MndFYofzq9fN82Gcc5cxkWJF52MXqvz69cgNa+BEGqD2P4VnF+/nrSL1L4p7TBS5zY4tr+WtEyItEMMtybdJOQDn0IM7s/+5J9pOWOAGoTk32EYKsYgdO/LaDbEcCvkfAnkmgLn16/B+fXrScnm5g1dD0MM7od8YG30oEZ+jABmmOuUNkrtmyGGWyEGdidce6ehQ2CPcb2JmF2AYQjB/RBDrZCbP0kyLFLresgwrk+IRYV3v49syO2bIHXvhaD44dz1Dhw7jIip3Lo+3l2tBtMjMnrEiNRkS/CP3sihRaKfweyRDbF7n9F2/05D91hkKPo9k7r3QmrbmBQhFIIHzBu02LXD7GZkKecRdM38fJowHUL3PuM70b4Jzq+TP39JKN0QUnSQ/DuSziK1fG581hkDmG48dEWRo99rGQnGNfr5E0Kt5j7msbJExdLQVeM3omOT0UWrKcbvYagFzh1vxo/XvMaIZnbvg/Pr15N/L5Xsvx2JZkdu22D0GsRQg6ZmEKM6x8xzuAMAwAQRTPZEl7VbuyYg6b1I+22LRWDDrRAjHZBavzRO3fU1xOAB88EmFv0TgwfSBncI3fsgdu009FICtt7vyWkUgdraKrubQGQgky7y/k/g2Pdx0tOt2P5V7lFi0ZumFNiT1PWVl0STlnA+IdJpRFWy5dxEfxTFrq8zJ7drkeQneKZDDBkj3xJHpYlKl/H0Hbvpx7p+cuRDSa3r4di/yvwRTcS56x2juyJ6Tkc0eiX6E9rIjCd4qXV92o+7oCuoqoqOsIrlq8C4uTr2fgg5gznL1o1kPv127zMiYdHtMkUgoCtGgn3q+53p2EyDmGA0nNtfgWP/J8mmNLEdideYwQAm3kCkzq0Z1ofSliWtj16ndOBTQOmO3wQTDEXs5iY3r0kz+7HjO/Z8CMf+T8yjJuZwSV3bTV0EJQBBDUJM6DIVYjfabG3Uk6OPUvMaOHe+bWiaEOEUIn4jUrP/P4YRjn4PzAhRrKusZV30M5ijCy72cJOa75TwECR1bI5HCDUFjn0fm4bWMHnRCGpqhI1paZ8NsWNLwvuXmVjCvXPX8uQHnQxIse+MGkzLg4sZm5qqhGuJdY1HOo33pQddo7EHObl9Exz7PoLc8hnkfR/BsfejpO2k7r3Ge+U3HgqkjrghdO5akf0E2drEdDh3vm1298eMOZOiDycxcyZI8e9xKPrwFeul6Nye/Tc6MTqY8n0SWEqbolozyZ31MhzNq5M0kds3QeowfpsExW/r/V627cxEv8Sx/VVotWOh102w5fxm9yTTAMgQupsht28Cc/igVDVl2auHSf1Jhk0BJGc0MsSyJh4D8R8ZuWUdAECRnGBVA+PrU29SCcdKNYFS5xYwZzV0V03cUKgB40YhOuNPu7H9Q4nvTxRNASRH8nb+3aZpTCpdwFRA1SF1boPYvQ/K8OMT3oME08pUsDxmJXWfNKLddgCgNh5qHFfthnPbMihN0xLauhNS5xaIwf1Qhs02lzt3pJdEEHQlY/K6GEk3sOnt0QA95bOSz5AlaOnY+TaYsyZ5g2j3tQDDkJnt6d5vfIcUf0q+VGpXXBeYoyppucA0iIlRk1h3OgzTkYpj/yeIjD7VSOqWsoyQS7jBSQnHSIz4JXX16wrkvR8ZBju4H1rtmHhXWSwSHDPfGSOk2aKmWb5Xerx9THIbn9OYaU0zbCwtwpbLWAuhFjDZm6RPKmLXDsj7/gOpcyvEYAt0TyMiI78JJwDNNyL6AKNBUMNgse9qMPq9iviN2m3R/DvH3pXQXfVJx3d8/TrUwUeDOeP1u8SOzZD8u6AMmWVsk/qwqSvZHxoR/yzFHgZTkfeuBJPc0JoON7bPkieGlM8ki0VSY9HkWBtE2dRcjHQCkU5AlKE1TDIHMkRGnxo9CIO872Mwhxe6J/67LUQ64di/CsrgmWDuhvjnMtZtH24zjGie0bVCaiQxZiQL6mEpPmTYiLIiMB1y+yZEym3Y1GBStwN0DZAAQTOeOs0fkYwUaNgUP4SIH3DEn8QEXQGzOgxfT77pOPavglo3Pm5yU25KicdMM3PRZc4D8Xw2Qdfg3Pk2dFc91CFHJ28cu4kl/PgKajeYVJty1Ph7ktTV074Zum94dL9ojl3HVkCUzfwswLiBMWfqMTOQI+9JOhAfqZl6QzW7i4F4t6UWhujfDd03NGveT66bbk60iJF/t/ud5DamRg2VbvPGCyTfGAQ1CKghyLvehdzyWdS8CdDdDWCeAYAgQXM3Qhs4DWKoxYjSBvfnjBbIreuBaF6ZUaJAhVY3Ec79/4EQbofcvAZS21cA0+CTPdCrRyI4+WIw75Dk62jdkHPgQ+xzJ4RaIbV9Ba12TNJDBoAkkyhEOlOioSxDLll0W6Yjrb57tshrps8L05PNhCCASd54F16qyWNacmRXV9MebBJJilAxBqnlczh2LYfY3Qwx2JzR8Egdm8x8PM033EhliH6PmeSC7m4EnB5U+/eanxG9ahDCY86AOmAyRKU75fdFhRDpSjJsUsc2CHoEYmAPmCv9uyaE2gCmQ2r9ElL7V5A6NkOIdEH3DoUy5GhIogzoKpirDnrVoGSzzpj5exozbBm/q7qanpMYe7+j0dCYaWSCnHYMQe3O2Msgdu813tdQi/FbAgECmBmdFP07obkbzDSExAdkqX1j/MFIDYE5vBCYBs03Akx2Q27/KkPk1vhsyu1fgWmHpl9nmSDDVgS6uixECoiiju6zQqIujr0rk0eGxfLLWMr/mSiwbEas21AZckzC6dSc5kNtnBwvFZHB1EldO03DlnZTShhE4Nj2KuTmT6AMnQ112HHGwgRTwBKOn+kGHLtRJb1XumL5PZACu5N/7LQw5DYjb0RtPAzBYDSpP9Y9wli0VUJaTh+QoUsj5VzmdhZKOgi6AvnAp4i4aq3n/WQiOoDAtfEJYyRm9Kak1k8Cc1ZDqxltRAIc3uSuxXAnHLvehdp0uNHFE26D2LEF8oHPAEECc1YbXVT7/pPz9MrA6YAgQqsZC0hOqA0HGyZZEKNV9I2bi9ixBa7N/zRGwbZvNLWN3dxSERU/xNYv4HvnZ9B9w6FXNUFtmgYh3AqtfhJ07xBzIAuTPYAgQHc3QgrsgfuzPydFLBkE6NUjoNWMhqD4wWQvIuP+C3r1CADGAIIkWIaBJEnrkiO+5idFNyJlhmHxQ2r9wsiN0iOA6IBWNxHQIvHyJUo3ABHwVBu5is1rkqOnugaBaWCxzx3TjUhPluwhsWOLkZ/Y8gXESFfW/FAme6A2TYXmM94TUemCe93f46NAExC0sPHZDhgPQ4lmxLPuL/GmOquhNk2HXjUI6pBjgMbDjPbGuv0cVRDCEQhKwMwNAwAhsBfOnW9BPvA5oHYnfY8AAK1fpEWfmeRCZNQ8hCaeC+fWl4zUgc7t0KsGx4+bwURLLZ+DeZKNe2ISv9i5zTBkDi+YwwutbrzRfsYgBnZDCOyFrAah+4ZCbv4UYvsmREaeBDHxQQcMumcAhOCBeMSQMUAJZOzJkHe/Fx3dK0BuXg1BV6AMOgpCqM04lrsB/rn3pAgY//z5A6UbqZsPMmxFIBSyp5BnxdGT+luJKAEADHD4LG2eqIuQMsJT0LWoeUkZCZSRLGZF6Ta69lK7sczdEpJhdQUsh2FjDi/UxsmQ2r7M2JbE6FRqdEHQI0b34NdvwPPF3wAAjuY10La+iMjwudDH/pfR3IFHGqYwQ9eFEO4wc0qA5ARiQYtkaHt2AyfoKhDxGwMK9n4EMdQCsXsf5LoJRjvVEOTWdZBavzTyV0QJYAzKiBMBLQR1yLHQ3Q2Q9q2CENgDuWMLoHRDrxkNQQ1Aqx6VFKUCADGYPQeRCVLSeyq1bzEirv5d0KtHJXf36iqkzq0QIn4wyQHH7vchhDsghluh+YZB0FXIez7MaHhixtSx72O4v3oG6gAj8sAcPoCpRheghWgtk6sQGn8WRDUEIXQAYmAvAB1i936I4XazGzjR2DHRYdxUZA803zAw2Qf5wJqMNywBDLqjGuqQo6HVjIE6YDKYswZCpBOetX+E3PoFpM4tyXXaLMIEEeqgGZD3r4LU9XXcmANw7n4HmndINIJzjHGjHDwDcPiM6Fu23wemQt670hipDQChVri/ehZS25dpZidtVwhwfP06BF2BGNgDqe1LACIiI06A7mkyBhRFuqDVjoWgBuDc8W+oAw6HVj3CiGLuXw0h0gmtYRLUwTPBHD5IreuN76kayhg90x0+aAMmIzJsbjw6JTrMz1msWy84+VJUrboLuqse2oDDoLvqDb3UIAQtYkRPZTf0qiFQGw6Gc+dbcG7+Jxx7P4SgqxAjXWbpGPbVM3CO+AbUQUdA8w1HzIyoQ46GoAYgaNUQggfgXve3tNpyxmfhGGh146D5RsK5623I+1YZkadwOwAGMdIJ15YX4NryQvL7KzoQbF6D4FGLIfp3Qgi2QG75HHrVQGi14yEF9kCV3HBuWwapeS302jHQvIPhXv8IpOZPkyLhgPHgqnsHQzrwOaTueNd60nf4/V9AqxmL4OSLjQeAaPRe7NxulP7RNYi148BcdWaurKAEIIRa4fn8wYx1HJMeIHQlPbUg4Tc3FKa5REtGOeYSbWqqRnOzvX3bFYEagnPnW2AAlFguQgHEyjtELO6bqEtqaYhYjoPYsQVy2wYwyQ1lxAkZjyMd+DxpxFPs/LFjalWDoTVMAqJPsbHlyqAZRlV1AFr1SCOZO5Ox0FUIoTaoA6cb3XZKF5Thx8OxbZnx1N69D2rTNDNiJnZshXPHG5D3r4ZeNQiifxccez80f4h0T1PSeZggITL22/Affy/k5jVgktvM5Uu9lkzozlowd6MZlYqMPtUopxDNsUtCDcG16f/g3Ppyyaqw654mBGbdAeashtp4aOZ2RGGiDGX4iZD3/ce4ZjUE34przRut7m6EOuhIREadArFjMzxf/D09fyUHypBjEB53JnTPQIihFkgdW+Dc+mKSUUlqu6sBghYCkz1gksv4DAabweQq6L6h0B3VCB98PpTBR2VMcmeCCEENw7Hj34Yh0xRjcEqkI2PkLDLyZKgDpkBQu6F7mqDVjYcY2IvQQecBosO84dfUeNDZGQQYAxNlwxjuWmEM6ujeD6ljE4SIH+rAaWCOauOGFs2F092N0H1DAcmD7qlXGl22rV/C88VDEEKtEP07IYY7jFHWevrDgtpwCMITzzVMpyhD940ARMn4XO9+D44d/87ZHcsEGZAcSQ9lStM0QHJC3vdxznzR3sIgQBl2HLSGQwE9AnXA4WCeJkCUoDtrknLEdFcdtMZDkx7w5H3/gRhshlY7Dkx0mKYfSNAEUSNTPTx6Uh1i+ya4trwA+cBaIz9u/ydZHwaYKCcZDiY6oQydBXXQUYAgQq0/yOxe1bxDzYgbc3ihDJoBSC44tr8C3/KrIQX2QHc1gDl9ELv3mw92uqveMFodW+PL3AOg1YyE3PJF0gNgKlrtWDDRmXTt5nvmbgAgQAy1QPc0Qfc0pRXm1apHQYh0WC4FwkSHEe1sPNTQSxAAyQ2xazu0hkOMaKTsyZheorsbUT/5GyW/32ebS5QibET5iN3AoyFvqMGkPIzytiW1S7QHEbYoUvdesKqB0H3DkpYnPqUl3cAZg+DfYd5IHDvfhitm/rxDoIz4BsSur1G18tfmU6ZaNxGRUfPAPAMgHfgU7k3PpbdS9iA84Rx0T/sJXFtfNrprdvwbUtd2uDb/A2LXDihDj4Uy9DgjmiFKENs3GVGmHIiRDiDcBnnvSoihNji2LYPUuQ1CuBPKyG9Cq58AsWMb5NYv4Pz6tXjOjbMaetVg6FWDzR9ZMdIJpWkqtNox0L1DoQ46ClLrl/B8/mC020YwnpZDLQAEw2h4h0AIt5smSww2w7n5HwgffD509wCjDIGmgLlqoXsHJ90QmbvRiOCJMqApqP73ZUm6iKEWOLe/CmdCJX4zoVsQwFwN0LyDwaoGg8luwxQwzehybjo8KcKiuWqgV4+AMnwuEDwAuXU9BF01ojqiA5ERJ0IdPANa3YSM9c1iN1bNOxSsahC02nGQOjYn3fj16pHQGg6GOmBy0g0uFiEVIl0QA/sgqAGjWzN2kweMrrjAXuiS04hSZ/rMCwLUQUeAuRsRnniuUZx5z/vR+l2qWYohE5FhcwCH17gW72Aow+dCd9ZAHXKskdMV2Aexcyukji2Q2r6EfGCtkdPa+gXkD29Jfi9SzKfuqoNWN8Hs7hPUINSGg6EOOBzKyJOMh4no90kIHjDz54TufXDsfh9iqAWabxjUgdMhhNrN6CGTPFCGHWfUr2v5HMxRDXXgVIiBvWCuOqiNhxo5f1+/BsfO5cZ5B06HVjMGzOEBcw8wzGoUtf4gM2eSOXzR7tQooiNrNF73DgFzViPiGwbHjjfTC5ok5tAJIvT6iQiPPwtabLBNYC9cW/4FsXsPAKM8hrz/P8b0VbGucFGGMnQ2/MffY5jnTEZWNn6PdWcN1KGzzMXK6FPRPuhIuDa/AN0zwBjI5BsO11f/B+e2lw3jGDXVetUgMIiQuvdADBl5i1r1SIQOuxjOTc9C8u+E2jQNWtVAqAMOgzr4GIiKH1LbRji3PA+18VAwz0Cje1SUo92bfuOBWJAgdWwyZjbY+yGkwB6zoDaTXNC9Q6C7GoyyHaF4ziSTPYAWQWTUyQhP/J75cG1oNhF67bj4W7D7/Yxd22rjYWaXvl2QYSPKhpBg2KS2DZA6tyIy/IS07i3AGHkFQTLC2qXA/LGK3hRyGbZMP2ypxWczBKrlDMU75b0foeqTu7OeSgrsgfTlo3B/+Wj80KIDcvtGyO3ppQK06pEAY9BqxyA0aSHgqgEkD9TGQyDUT4Qy+hTI+/4Dz5r74Nj/H6Okwpp7wSAgMvoUuESnYUxkD7T6SdDqD0rKJWOaAvem/4Njx1sZR0o6mtOjQJpvOEKTL4FWP9E4huQyE49rJp+C4GevADCiIHLLOmgDDoP/+Hvj+9eMTogWDjC6y7SIkSR/YC08n/8Zrq0vQfTvgWPbq2Y3cAzdWWNcB5hhNBxVRhdoYK9p1pTBRyM08Xtw7n4P8p73IGhhY6TwsNmIjDk9YwK8Wj8JQqTDHAXJUkZMJkYx9NqxUD0Dkq/FWWt8brJ+1oz3PXZT12rHGV1ivhGQWr+A1PU1mBj9yU4xTrGkciZ7oFaPyFh8lslVUIYcbZRsESWAZalzJjoT9one2EQJQLQcQ5YcuKT9ou1jnoHG50uQwVw1UIYfH09SV0Nw7HkfUvtXhoHVIoDkNGYGgBHp0xoOheYdjPBBC9J+JyKj5gGCGC+5EsvdShjswKoGITL+OwBgGl+tdjwiE74LJeH7aXTFDUmrrxbbRxlxotFlD0CrGZOxRAsAY2QijG5GrfHQ5PywDL8jauNhEEMt8cECMTOdEt1hGQdksGh7xkICEJp8UXyN5DJy1yQnxFArxI4tCE/8HvS68cZpovXIdFedGZlSBxwO3VUHqWNTxgFBzFlrmlPdOwRMlKEOnAa1aSrEjs0QtBAiI08yvh+6CsfXb0AMtUIZfjzU+klQh81CZNhsSNHRwkyuMr6rA6dB3LUCum8oQlMuQ2TENyGGDkBqWWfk6woC9OqRpiHU6iZAq5uArm/+Ge51f4MYbDaihIJoPjCY3aDhdqgDog9Wupo22h1AfBYJ87WcMR/PbrMGkGErCuGwfUmIFUUsR0WQzGKMghYGy2DYYiOvrHZ/ZiKXLgIzctiEWImyWE2wto1gsifly5mhvlaWoe65kPetgmf1/8SPKldBd9VC7N6P7qNuQHDa1fB8sgRVq35rDiwIj/sOwuPOjM5zuA1Sx1boVQMRGX0a9Jp4ZEx31UMIt0GAYXLkluhTtSBCHXQk2v/rRbi2vQLn5n9A7tgMAcyM6iXCZA+ghqDVjTOSuBNKMTCHF8rgmYAgQfcNgxDugHPbywBjRnSRaVAHTEF40n8nmT6tZrQZdYgI8Ygq8w4G69gCIZLSTZaQy8SkqGGIljZRB88APv8zAMMsxgyj7hkYr7EV6YSYmtQeO54gIXjE9QiPOxPMVQfmG4rwxHOgeYdCDLfnnqtRlKDXjo2XrcgyqtForwuR4ccDkjueMyO7jZygLLlaWu04SJ3b4pFaUYJePTK6Nvp+Rgu/JprFtC7wBIMcu2a9epTxmU4oTprYfkVJfM8Tvo8Zyngwhy99aivAiIbEkD3m9RvrHGnnhOw2jVBo8iXRi9EgtX8FzTvYMIC5IvCxY2V4WGIOH9QBk81IJhMd0L2D412UKaPCjUEU6Xoyhzc5SgZkHHEZX1eHyLC5WdqdweTK7rTIPJPdEBR/siYpZTyiF2GsE9PbLWhho3vZMxAC06EOm22atcS26NWjTMMWM2OR4Sekmxgg6bOgu+rj3duCYB5bazjY+H6IMpTRp8T3jbUxcWCRHom/59HvhDJ4BiA5oobQAXn/KqhDjoHY+TWQ2i0uOaGMOBFSx2aodeMhqOF46ooggjmrjUFAjYdAFcTsNeSEFBsk5rZFdt7vybAVgVieAZEHczi3mPBjmyF6lXpD68Ek2kAeXXTNeApLCJtDV825/HT/TmPkFZDxhiCmFRONzXeY2chJzWvg+eR3EJgOzTcCgZm/NKJh0eNHRp8KCIIxkq5qIJxfvw7d04Tg9OsgRNoB2Q0Vc7JeDnPVQaufACHcCcju6E3VH+1+1qHXjUP30b9EZPQpkDq3Qt79npGDonZDHXC4MX3L7vcgRp/sE4vYMtmD7mnXQqsfb3aZxAhPPNcwDKEWqPWToNeOgRBqgdT2VTzvKKH7obMzCLF+Iph7QPTgevQc8VphWv2E+A9vyo8nc9agc95SuNc/AiHUAkENgTl8CB16IZirFkL3fojdew1j6x0KJjkht280BgxoEagNhxhG0WVEC7RQS3Suxtw/hVrNaOjeYYAoQW04JNrFG79RMskNQQtBdzeCOWuh1cQHRpjXxnRjBGCGAsEAwDwDoNSOydkOc9sEHdRBRybnIMqeJJOhDD8hc2QBRhceczdADbVBDka7WLNsayI5EZ0YAcqgo+IJ26mjfBN0N9/fHOVztJqxhvkQJejuhuQyPKntbppq/h174GOCaJiTWL5XwvdWGfENiAnJ5iz1cyW709rPBMkwbNHtlWHHQ+rYZAwiSGiH6N+VnJuazWRaTBePGebYiOpsD6169ShoWhh6zVggw2eKiTJ037DoQ1fKbA7muTJ0cWd4gI6hNh4KIdwO5hkAIUPNvkSjp9ZPTCsgnKipoKvxqKizGkIwBOZISGfwDIAyal50x2h0V/akDSCLoQ04LHl2hdhxEiNvGUj7LGQyqwnYeb8nw1YEEpNDiRwk5rCZP44ZRrGlPL3nnEQ7tk+oFYLiT4hI5NNFjyait5tL5ITRU4nLM3X/CFooJZLBAKXbHGSQiNixBVWfLIHAdERGnoTOU5+AGGyOT0ckJJS0YBqYdzDCBy80Xktyxif/RJRBRxldMYJo5GzBeFIV1JA5f6EZqRIkMGdN2qAPdeixwKT/htS20bgp+UYYc+1JTgQPuwTKyG+Y3XLJb4QYvbm2mIaLuRuh1aoQ97dFz23cALSasYYmiOeL6L5hENu+hDpwGhy734teswvKwOlw7P8Eurs+vftJciJ02I8ARAdAdGw187mYdzA072Bo0Ru6Vj0KwcZDDB38u8z33Lzpxt7baNdwNrSGg+MvEh88Yotkj/GZEB3QGg5K2lcZcgwEtduYfivYnNa1HOs2zVVPLY1EM5QCS12Xw4zqtWMBANVNQxDKkPQNAMrQ4yCE2+KDOwQpWnxWz/vZNNsUbQPLUc9MazgIQvd+wyg5a4AUw6bWTYDc/pXR7oQ6ccwzIPodaDTy1zyN0XYKiAw/wbjBJ3zHBLD0umop75ky8EjDRES1EqLdaUmfg2g7mCDmHKUcb6jFwQ/R7jiPx2matoyIktke3VUHIdKVNNCHyV4zKpY6/VZ8m+w5iRmbVj0SiP3GRiNsSYMaEj8PSebcOL/uHZr8fY5uozZNNUrzZHtYELIZtqimubxwzhqbSP8s5NHJzvs9GbYi4HLR25gLx9dvGvlMsR9tiDCf8aLRNHnPh2DuBmO72Bx/eaIeSeeIlh9QtQikwG4ow+bk1kXX0obkZ32iz/REpylgzloojYcYtbiApFpgUssXcOxaAa1uPFybnoOghREZehxCh14Y/RHNYg5ScieYIELIcFNUBs+AEPEbXcqeAenHkVzG07PkMt7PWBQixw0TkhPh8d8xb4rqoCNSnu4zt1mvHgU93GZElcxN4+89kxxmvlGqJnrtGERqRqfVqGNVg4x9sjxNM8kNLZZQb36uMuRWJYxKTIyMmCYmlpCdrYJ/JmLnS7i5mJGKTJ9ZyQkmOcFcdVBkj1nKQBl4BCT/zmju4KSchtE8l9m1mGvblGvJsW0Ml0tGtnF8ZtdSuB2Sf5fRzR6bwUJXobvqzAeFrJjtjn/+lMEzANERN+ow8s+Ukd9MioYBRje/Xj0KiH4209oY/Q6w1NlKZHc85SLJTMR1in02AcPgM1edeZx80ZbEa8r7e2XRsOm1YyEwDQ6HH0GLvkAdbBTAdm5/Jb5QMgY56J6B0OqzFCoXCzNsSe30DYcebIHuGxZ/+ISRlyco3RmNktYwCbpnQEJUNvbAJJv5f5mI5fClRgS1mpEQQq3QakZm2i16juR2KEOPS571IUXjWBHuWMQ2FTvv9+Q0iNKiaxD0CKSWz6E1TjaWiVL8aVdXwRAt4hpuMwxbnq4DsWuHkfeRwcjICT/orGMHRH930iiu+Mr4k6i8/5NoTbBWMGcNIqNOSRpllmn6FkFXoEs18VFrShBy5zpAi8Dz6R/i9at2GhNj6+5GhKZcFm9zlpsoc9UCiQVhmY6MRTsFOSmHLRvK4JlG+83z5omIJOY1DTk247pomds4ksMoEZDlOBCk3OcVhMxPwUKCsU9B9w2Pz/xgTnUjpRne5Ar3xnZ6grkwIwO5THSGc6tMM6INsa4oMzk/9w2eeQdD7zK6+5inCWrKbABZz1k7DqroSMp3UgYfbZoAZcixxmhOwLwJM7kKasMkS8c325ej68h8nxMj5JIjnjqQ67hmJCfhuy06Ms8wEisAnEDi5ytzAr4VzI7AZHOVcDwtGo2Nt1GCMvCI7FNyAabmWjRamQhzeM1R02bkLw/MVQt10JFA69uWtgeQ5fdEAAQR6qAj0taYeY/RBwE900NfPiSXkVOaMgArlv+bOP9ukqFPrPdodZJ38/MW/Wwj/lodMjP3vtGH1Miw2dGBGMmRbJaSw8ZcdUC4FcqwueZUV7xAho0oLbGK4YKUYJISbsRMS/vCx6MkgjGtUQpyy+fQlO60rqdERP9uILIRcmcQkZRpdoAEY6eG4Fn1u+TCql070D3jFxBb16Nq9e+jFbgPgp74FBetpG5eR7gdQqQLnk+WQG79Ii3xWxl0VNJNKFsXhV4zGhFPE+QDnxkmlmWZssfqTcvhhZ54E065QSaOEks9bnpydcKPZoZRiEkklSGw8DOT7XqyGFvdG4+WxW/gGY6R+IQsCEZCeGKOjlnyoIAImyBArxmdfJrYjSRXBDOKOugoI3JoIfIVP6eYfk53PBE9USuzLY4qsMSoYh6MZPNcWsUGPhRumJhsfAYTpxBjQvbu/sSbquaLlyaJjPhGvB2FkniuAqL3qVNspa131SIybHbGgt7KkGPN4q25csPKjdo0zYw+R4YfnzTCt2Akh1HKI/U9jT3giQ6jREeUxKillvKZzoagxb6nRnmcbDNPZN45uq3DZ5RaARAZNjeeapPSbq1+ArTqEcnRWU4gw1YEqGhuDhJzG0zzJsS/RLpqzudpkhBhy1RM0dgvbhiEtAEAgBBqQac/etzEYp2MQTrwKaSOrWDuBji3vmiatfDo0+CK1hSq+uh2I3k+WkmdQUBg1u1Gzg/TjfkNRQfErp3wLr8mafi+7qpD94xfQPcMhGvTsxAinYiM/XZKA3PcdBxeqAOnQ2r/yhjZ1pE+jVLuuU9zkNC1oIw40ZhHMsmw5ThutM1MrspYNiJr+xJMTNbvStb3I75cbZxsJKSnGvDYvqKUlBKpu+qhDpicvG1qQnisK1aUo12qPcTsdrNoTnNFsnoJi5YTsXozBKK65Ls5WY3SZiIagUz63OQwTWYXp+SGlqhhIV3XaSSoa0WnQsg2+4ooF2QOE2mVx4ANsjarS8GIEiBGo8I58iGtog6cnrYs9hvAHL7k73fUsOmuejDv4LT9MhL7vY+leeRrT/2k7PcOIPl3IJPRzDE62c77PRm2IuB2O2h6qiyY814KUryCfOLNnKmAmTMQXW5GRXLcPmNTSoU7MlaEF9QgHA4JiqKZT/Vi1w54P7g5Y1FE/zG3Qa+fAIgOuLY8DzlhsnSjJQy+936O0MTvQTqwFvL+NXCr3XDsfie5irjkQuDo/2f+EIUnfR+6uzHDFDZ5rIHkNIti9irClrZfLN8mmoyclu8kQhk6K62bILrS2Ef2pA+xz3Ke1Lb25rui+4bm6VpNXqfVH5TXGOm+IRDbupJGXRZCrMvLjAj18OZcVAQhLTk+H9Z06UWELaqD5h0cH4EsytnzugQRypBjreWQWW1DYhmQ6EOE5utZbS0jmtTTrllrOAeO79V9Je3Bptxk+5yIMpRBM7JP6ZcB5h4A+HdBT4gqZyIybI7xMO2sBnIZNhiRW8m/M+/nWRlybNLvpJ33ew5+XSqf6mp3/zRsWth42mF6tChhhqdfPT4yVIgkFoOMGi5di3eviTLkff+BkM8MJJCtbpYYaoGnxgNFCRoFOdUQPGv/aJo1tfFQc3650JTLoAyfCymwG6FDzkdkxIlGEq3kglp/EMRwO7wf3gwAcG98Kv1t8A1DeOJ5EEJt0KtHmGaNiTKUEd+AvH912j6Fdetk2LaHETbzpmUmzqcUYI2N0Mu4bwE3bMkF3d2QdvyCvytJkbfc7xmDmLyFhXbqteMQqRmTnJdVAMrQ2QAYwHRjiqY8NxResaRLrq7nfIgyIiNPNnLCnDXGaOM8+uSqd9YjUvSNjJqHnnavKiO+UYQG5aY395XYe20ruQbGWMzni6H7hiJSNSj/NTm8FmbrNdAaD4s/FOcg9XNo5/2eDBvRI4RIFxy734XacAiESCck/87MsxawWAFXKV6uQ1fiNbpi+R3GUZOHx+e8gbL4/tlweAAEIahBeNb+0ayx1n7W62kjQrWGQ6ITYHdA0FUoUdOl1Y435rPTwnDsX2WUAgm1QHfWIDzhbIQmnW9MH5Xx5mN0/SYmSZsJ7wWZgww/QT2NsEUjHWbXVOow+nyDA4w/8p9HEKAOzpMMnIH0ulCJ3VhZzhvt0mHuBiCxJIzV9zjLNSsDjzRmhsi5rwAzuXvwDGvnq1DMiRF6YGwBxGtpVQ2CmlpWpSyknKs35y5ru62jDDnGyAm226wBCT9bPU40SKbAa0qdQzWN2He3giDDRvSMaPemGGoxproBIAb3J9VBA5D0hYkNkU6ayJlp8cEIPbkR5PxCGnOW+t6+Ao69HwIAAjNuhDp4Jhxfv5k8EbXkgF47BlLzmqRDMFEG8zRCazrcmFLn0AujAwEEI1TurIa0PT2HLomEoo/qwNiILXsMmzlPZuzaU5ONcx433ubIiG/AuePNHrUhG5HhJ2SIHOZ/n5izBsrQ48BEhzmvoNV9c50rrUQEUdmYvy9WYzCVR8mm8qtAlGHHI/cc0ZUHGbYi0NHRs0r8lYxpvhIT/jOZp+gyIcsXR2AamLmucMOW6wmqe+9m1Lx2sfk6PPpUaI2HAQCUITMhH1gHMZxSey01lylTTlIs+T5vfk3seqKJ/g5v/CmxIL+WybD18MlQdkOrHWcO4y+sZpcQ30ZyQhk4PblshgVyflcyJb1bvE7mrDa6vhOXFfoeZdhebTyssBptNqIMPDL31Fo5KOw3rLhRCbVuQs4aXEWjp98Zm6j4+0os7aKEA2xyIjkAFC8HMoadupBhKwKqarGCdZ8iw3RNoVYjdylxbrzYoINsycVqCLJp+lKPmX/QgTnyNAWp/Su4//Nb83V49KkIH/KD+AYOH9QBh6XNL6fVjYfuqoXUsQViuD23KbNau8sM5SdGrwqPsGm148xu3d4Qm5TdaFIBP2ipU/dUDSo4VlH4d6U3uX69v0HzMOGzVVhVU49jR1Z0yVlNvhckz3FZSirLsFX6fYW5aqEMPCJ/UeUKw05d+OyIrzAaG0s09LpMyPv+AzHL/IZZyWDAkqZbiiLkMVZJ0/RYnbolcXs1Q312XYXnk/+BGOmE7qxFaNL3EZ74vQwHyJTMLxq1q6wYGVFOMjFZS22YBUetJ9An7V7sXJCkg5f3J6Dg70pBtcpSti3w2rT6SWadpv6GNV2MDyKrLN+TQKz2Y2V0iVb6fQWI1rDjIZ+uiNipCxk2wjBaWaZ8yU72Hz0hqYRFbDRodPBBLtORMj1Rrpu1AAbH7veiExsnI3VsMcpoVA+D/4T7jBpomWoN5bihm5W/802EnUDihNTG8WNdp7FyJSxtHQAoQ2flPG6sS0F3VltuSyGoAw63VtfNbH8579jli7Axdz2UYbML2qd/UqGOjdOBAgRhFeoSJTIidu0ABCltWicxsMcwVjmiYY69H6XMQZmA5IyX8WA6pLaN0GrHGseFYbak9q8QOuQHuW8LjEFQ/BlXybG6bBO+lbvIYi7DVjMaiqu+wNICArTqkekTpMcS+5Py+BIic3nqEem+oVAcXqMtFuaYLhSjvpkAuXkNmMOCKSxnLlCvImw9aycTHT2bqqevUyGRqaz0g0EHRN+GDFsRCAYLS7yuBOSWzwEAetd2gDGoQ415JeXoKEq1Pj5HIRNlw0AlGhKmw7n91bTpSpjoNCYsl1yQDnxm1jdLxbnjTXQdf1/eaWFSESKdcG59EQAQGf9fgD+zqTM27nkdKLXhkPSFggCt8VBoNaOTcuPMPLjE96dAM1H0mlQp6N4hGafwKjal/a4UJ4dNGfnN3jelwihIlwpL3o/R8zlI7aEv3lf6AnbqUlmfYE7x+/PMq1jBiOH25Dwzk/hTqjpgKpgz2VAIEaMeVtIsABDiXYyCmJbvlornswdzP9XrKhzbX4Nn1V0QonXVnJueg6ArUJqmonNAnu6tXpTGyDzxemqdstiUScY1J49o7Wn0x85nrN5HJkr6XUkzEpVpLOzAmi6VHpmqrM9DX76vVDJ26kIRtiJQV1eF9vYKH4JdKCmTaqcmlsYMWyJ6zSijG1NXIQb2wv3VMwCMml6RMd+C7hkIMbgP0FV4P/gl5JbPIHZuNebvzHB+z6f3w7HnPQCAY99/EJhxE1zblgEAwmP/C3V1VcipSrGfuLMVFo2Z1ETz2sMohTL8xB7tV1x6fuMr63elwiIqdlKYLpVlfEwSp6aqAPrlfaUCsFMXMmxFwOGo4FEwPf7xStxPSIv8CJHO9F2UAHxvXAK5I3lEanjst83pnHTfcGPTocfBueNN+N77OZQhx0KrHQsh1AatYRLE4AFILevSqtB7P7oVgJFEHzr8clSXTJc8N6yU95SZOWy9j7DZO+Kq9ze6sn5XKrTrzg6s6VIZRic7lfV5qOj7Sh/GTl3IsPV3Ci2lEUVI9muAkG7YpOZPIbVvgjJ0FsRIJ2peTi+tER57hmnWElEHTDEr6Tv2vA/HnveNFdteStouOPlS6J4m06wBQHjMtzKPCi0WWX/3oyuiAx202jHG61gOm5550EHlUSltr5R2VgZ61SBIndvAKnVABhl4osIhw1YENK2CCxz20LAl7yekdT+JXV+j6j93QmAaXJueTRqQEB5zOpQhxyAy/HjI/p0ZD68OnoHw2DPg2vKvrE1QGw6BMuIEAEDnSX+HoIUgBvYiMsLoNiydLtl++GM5a1LyKFlRglYzGnpVgjGtxJtHEbqSyvpdqcT32Cas6MLcDdlHf1cUlREprOj7Sh/GTl3IsBWB1taA3U3oOVbnWmN6iinLbtiE4AFUv/Xj+OuEc/jnLIHuG2ZMgp6rrpggIjzpvxGe9N/G60gnlEEz4fr6VYhdO6AMPiZ5LlBHFZijCpq7wew2bG0NwMqkQrqzwBGY2YxADoOgNRycunFh5+wjVPR3pQ/TL3SJ9gLoZRgNXQz6hSYViJ26kGErAlVVTnR3V+gQbKsRNl0DpATDljroIGbYNAVVK+Pdk92HXwHdOwSO3e8jOO0nRjmP7r3G9tGuQgYBuncwpMAe6I5qiEr6gAV14BFg3kHQq0dCrx4J5m5MKdCbfk1VVU7kmBoeABAZ8c0e5IXlibBZOkTlGTbdOxSsfRO06mH5N85CRX9X+jD9QhdRQmTENwqbjs1G+oUmFYidupBhKwJer6uCv1gWDRtTIfr3J7xOzseK1TiSm1dD6t4LvWoQuqdfB71mJAAgXDceWuMhEDu2RHcRwczJvhm0hkMA2QsmeyC2fJalEYkmJ0e3RrTrzut1IVNBkiQKmMkgczsSF/emKn8F4KiCMvqUXh2isr8rfZd+o4tkJebOB/1GkwrDTl1o3Hs/R7AYYRNDrcl107JE2GKFdSMjToTWmFxcNnEidSaIYJIxMEAAAMkJrX5CjmgXSzZEOfya1Wuylwo0bARBEIRtkGHr71g1N1ryE4WQOuIxatjErh3G5rXj0yuLCzJMoyJIgBlhS2hOtjktRScSTY6Qods04Sg51hWBrJG0vt0lShAEQdgHGbYi0NZWwcmhFg1bcpV+JHWJsliETQ1Cbt8IANCrR6QXLhWluFERRHN9UtJ/hgib7qyBXj0SSYYtOlG8mpbMH7+mYuqiDDkGWs1o4/BZjFlhxXD7p2Gr6O9KH4Z04Q/ShE/s1IVy2Po7Vks1pI4mTS3rARHu9UsBAFrVECjD50LsNCZBZ6IMZdicZAMX/Tsy4htGtC1GhoRg3Tcs2u2aweRkrGaf/ZoS50AtBOaqA1OiX1SKsHFPZNhcu5tAEARRVCjCVgTq6712N6HnWO0STd2OaRC698O59WVADcKz5l44dr4NAAhO+4kxdN40JaJZTDZuaqIfPcmZFFVjQoZnCNNUZjJsGbpQo9un6qIMngk9Vsy2J+RqR87lvd2271C274r5eSOsUNG/YX0U0oRP7NSFImz9HquGLTnCJjANro1Pwbn7XbjXP2wuD4/5VnywQa65HLOtyzi5edQo9TrC1luTlKMduZb3dluicOj9JQiij0ERtn5ObPBAUl6WpqRvp6T02+saHPtXJy0KHnohwgefn7hX9L/0chxZ870yGLbY/KKZDBeDALVxcnIeXLaoYdFu4sWIsBEEQRCEdciwFYFAIGx3E3pBejTKueONtLViuC1lNw3M6UtapIz4ZvImmaJfsW7FbKNBU/bRasfHaydljLAJ0KuHQ2s8NO0c6boUKcJG9JjyfVfIPBdCZf+G9U1IEz6xUxcybEWA1+KGQrAFUmLttEzEolFZok9Zb3u6CiHUar7MOGOAab4yFLzN1V1aEOlRPL1uHIAMuvQ2wpYvh4264fLSk++K7m6AljgPqxVIi4Lg9TesP0Oa8ImdupBhKwINDXwmhzr2fQTJv6skxxYiXWZpjfDob8E/644MG6V/vMyitsU2bNH/mVxlzhXY0OCF7qjOsG1PyZPDRlGdvPTku6IOnglt4LQStIaIwetvWH+GNOETO3Uhw1YEJInztzFn6Q5jncB0SG0bLZf5kNu/AgBo1aPQdcqjYN5BCWsTaq1la4tFw8byeaCoecqUEydJItTBMxKOVeIIGxm2vHD/XemnkC78QZrwiZ260CjRfgFDVjORYNCkjs1gzurM2yXg2LkcnrX3AwCUIUdHTVOOEZxJRil/hC0y6hRI7V9B6ticty2x8wosS/Qrae7A3hkq3TcMemC3WUA3vSmFHV/zDgHzNPWqTQRBEET/gAxbEVAULf9GdsIYhGCzYcbSpoNKiajp6SNEExEDe+D+/C/GnrIHyshv5tg6g4FhsVGiuUp+FFIewzxw2jnTdellBExyQh06y0pjLKE1Te1VcyoR7r8r/RTShT9IEz6xUxcybEWgvb3b7ibkgcGx/z8AAGXQUWCeAQmrCjNsro1PQ9AjYJIL/uPuBHPWABDAHBn69TMNOsg3SjT9IAWtTyxPkqZLqRPRKdE9L/x/V/onpAt/kCZ8Yqcu1EleBHw+zquqJ5gyx76PU1cmvRK0lDlDUxCjgxi6Z9wIVhXNWxMEQJShDJ5ppTHxfYpCLIfNMICJpUbSdSFDZTfcf1f6KaQLf5AmfGKnLmTYioDH48y/ka3kH3Rgkq9LNNhsbJaxzEKqIcpkkMzKbjnPY3mO01gUz+GFMugoaI2TzVXl14UMYT74/670T0gX/iBN+MROXahLtD+QOnF70roCDJsSgKB2g0muzIMTUqJm5gjPxOV56r7lO2au9UldvT05Vm+hLlGCIAiiRFCErQ8idO8DtITifjkneE/pEmXZu0TF4AEAgO4ZkMWc5B+Jar2sRylmFSBDRRAEQVQmZTdsLS0tmDt3LjZv3ozt27dj/vz5WLBgAW6++WboumEsnn76aZx11lk499xz8dZbbwEAQqEQrrzySixYsAAXXXQRWltbc52mrLS0+O1ugokQbodj/yeQ2jbEl+WIsAmpvkjPbtgE1Ui2ZA5flg3yd4kK5mTzxTFPuUabputChs1uePquEHFIF/4gTfjETl3KatgURcEvf/lLuN1GaYk77rgDV199NR5//HEwxvDmm2+iubkZS5cuxZNPPom//vWvWLJkCSKRCJ544glMnDgRjz/+OM4880zcf//95Wx6TmSZn0Cl2L0/+kdCb3cBETboOcydGjL+kFJLg5hb5G2fpbIeBR0z+/o0XajL0nZ4+q4QcUgX/iBN+MROXcqaw3bnnXfivPPOw4MPPggAWLduHWbMMCrRz5kzB++99x5EUcS0adPgdDrhdDoxcuRIfPnll1i1ahV+9KMfmdtaNWyiKKCpKZ5v1dYWAADU18fLUAQCYXR3R9DQ4DWrGCuKhvb2bvh8rqQkw5YWP2RZRG1tVdJ5mpu7ks4TDqvo7AyipsYDl0tO2s7tdqC6Om56Ojq6oao6GhvjkatgMAK/P4y6uio4HMYISE3T0doaQFWVE15vfKRK4jUx5gKYB8EqD5ROY0SL2FAFBDzQNA2BQCTpmpjgRVenUb25qsoFuKqAsIpgMAJF0VBT4zHPo7YY0TfRVZW0/AAAt9sBX20N4PcAzip0OiXoomhs56yC0FSNYDCCMNPh9TpR01QDwVGV9Zo6OgztGhp8EBqqTZ1URK9JNHRS67xoDyCjTjGNWKvRVr/biVBEL7pOEQBerxO10eNa0SlGbz97XV0hhEIKF589K9eU+r0p9jWx4FB0t+yFKgplu6a+qBNdE10TXZP915SKZcPGGEMgEIDPZ1zgsmXLsGfPHsydOxfjxo3Lu/9zzz2HhoYGzJ492zRsjDEI0aiH1+tFV1cX/H4/qqvjDfZ6vfD7/UnLY9taQdcZWlvTt21uTl/W2hpIW+b3h+H3h5OWRSJa0v6xNzjTMTs7g2nLQiEFoVB6cn+m/TPVfOnujmScgLa5uQtSawBSVxAawpCi7VcOdMKR0I7Ea5Ja/ZAYoKo6OjuD0B0yRCW+bWL7Hd1+yABUOBFKvK6G6DV1BeDsDILJAhSfBpExdMZeR69NaDwM/rb1UNoUQIhfb+o1SRoDdIbW1gB0Lb6dM9r+GJGOICB7MuoUe0+c0bZG6lVAEIuukxNAIBBBJGV5Lp1S6elnL9cxy/3ZSyXTNWXatqjX5J4MDD0M0FnZrqkv6NTUVJ20ri9cUyqVdk2pmvSFa0qlEq+pqakaqqpn3b8Y15TNtFmK7W3YsAEnnngi/vznPwMA7rvvPlxzzTVYsmQJvvOd7+CDDz7Ie4xnn30W77//PhYuXIj169dj0aJFSXlogUAANTU18Pl8CAQCScurq6uTlse2JTIR6+JM6AbNNUq0gOR+QYt2iabNlpB1j/SzVTVBGTanBJO/F3tboiIRREC0WpSZIAiicrB017zrrrvQ0NCAM844A93d3fjrX/+K7373u1i7di1OPfVU/P73v897jMceewyPPvooli5dioMPPhh33nkn5syZg5UrVwIAVqxYgSOPPBJTpkzBqlWrEA6H0dXVhc2bN2PixImYPn06li9fbm57xBFH9Pyqi0xXV8juJsSJjcJMyFsTCslhy0U0h41lzWFLPVYvDJLlOmzZzxHTRa0bn3dbojxw9V0hTEgX/iBN+MROXSwZttWrV+MnP/kJxo8fj3fffRfhcBjnnHMORFHEd77zHWzYsCH/QTKwaNEi3Hffffje974HRVEwb948NDU1YeHChViwYAEuuOACXHPNNXC5XJg/fz6++uorzJ8/H0899RSuuOKKHp2zFGQKtdpHumHLOejAqjFCPMLGLEfYikBek5V9fUwXvW4CIqNPLWKjiJ7C13eFiEG68Adpwid26mIph00URciyseny5ctRW1uLqVOnAgA6OjpQVVWVY+90li5dav796KOPpq0/99xzce655yYt83g8uPfeews6T7lIzTXgAlb8LlGkjBJVBxye27yZZqvwmmq6uwFS1/boXKW5yG7YuNSln0Oa8Anpwh+kCZ/YqYslwzZ16lT89a9/RXt7O15++WV861vfAgCsX78ef/jDH7jqniRYyv8oXoRNNZI5YyaNObxgrtr4BnIVmOSC2nCw5WNmbZZ3MCLubwBSnmlAqJuTIAiC6AdY6hK94YYbsHv3blx77bUYNGgQrrzySgDARRddBFVV8bOf/aykjSQKIGrAhBJE2OJdop4sG4hQRpwIVjUwtsDysTOSz6wV4xwEQRAEUQFYirCNGTMGy5YtQ2trK+rr681SHH/9618xfvx4SFL/HpUVDmefHaD8FJjD1pNBBzHDVsA8nyUjxznKpYvuaYIYbC7LuSodvr4rRAzShT9IEz6xU5eCCuc2NDQkvT7ooIOK2phKJVPdF9tJGiWaw5T1ZNCBqz62pCct6xVq42GArkA2p97K3oZy6aIOOrIs5+kLcPldIUgXDiFN+MROXbIatmnTppmRNCt88sknRWlQJVJT4+Hny2WW9UjMYStOl6gY2GPs4TaMO+vFCM6eolePMP6IGbYcbeBKFwIAacIrpAt/kCZ8YqcuWQ3bhRdeaBq2UCiEhx56COPGjcNJJ52EpqYmtLe3Y/ny5Vi3bh0uu+yysjWYRxKnwSgHYuc2CGoQWobkfiFj4dxcXaLpMMkF5vBBUPwQtGh1ZjUEMdIJJjoTJn/nO3+s3LoQ+SFN+IR04Q/ShE/s1CXrmWMDCwDgZz/7GU4++WQsWbIkaZtLLrkEN954Iz799NPStZBIQ25dDwCmYROCLWDueqPKe4bCuakRNiHUakbJUrtEY4aPyR5zVCgAiKEWAIBeNaiA3DQh4zkIgiAIgigMS6NEX3/9dZx11lkZ15166qmWpqYiSoTih2PfR5BaPk9aLOQYdODYu9IcQJBrFgQmxAeTOLe+BADQ6hPzFvmOsBEEQRBEX8GSYauvr8eaNWsyrnvvvfcwaNCgYrap4rCzuKGgGyNWhEisDRmmptIz5LDlzGuL7Wh8PITAXjh3vAkmOtA97eqE9RyMEs0BFZ3kD9KET0gX/iBN+MROXSx1xn7/+9/HkiVL0NraitmzZ6O+vh4tLS14/fXX8cILL+BXv/pVqdvJNW63w8bpKlK7HTMUzkUPy3pEDZvYvQ8AoAw5FnrdeIgHYl3g5R90UAj26kJkgjThE9KFP0gTPrFTF0uG7Yc//CEA4C9/+Qsef/xxCIIAxhgGDhyIX/3qVzj77LNL2kjeqa522/fFikaxhFTj1Zs6bKl5bWq3sdhV14MG2oetuhAZIU34hHThD9KET+zUxZJhW7NmDc4//3xceOGF2LJlCzo7O1FXV4cxY8aUun1EXlLm68w46CCTYctQ/iPjcQFoEWNTV21yN6flLlEadEAQBEEQvcFSDtsVV1yBl19+GYIgYNy4cZg2bRqZNU4wa6GldokWZaaD6LGj50ifiJ0GHRAEQRBEObBk2JxOJ5xOK/M69k86OrptPHtqhC32MnHQQY6pNNL8WrqBE5QAAEB31YIlmbTcho3ZbOjs1YXIBGnCJ6QLf5AmfGKnLpa6RH/wgx/gpptuwqpVqzBu3Dg0NjambXPyyScXvXGVgqoWVpi2V2SLlmWppwYAyGDYBMZiFdcyHSypuzM2ApU5C+wStZmy6kJYgjThE9KFP0gTPrFTF0uG7fbbbwcAPProoxnXC4KA9evXF69VFUZjo698Q30zlegAkHl0aGyfTAmSObaPEesRVfzGlq5aCw1M3N9eQ1dWXQhLkCZ8QrrwB2nCJ3bqYsmwvfnmm6VuB5EBIdQGx94PoQw+2pjJAEiun8YY0gcPZOjSzLDMsfs9aFWDLc1CIESihs1ZCxTQJUoQBEEQRHGwZNiGDRuWc72i0NDjUiAGDwAAhNCBBMOW2L1ptdZaZqTuvdDTBhIkHleAGNgD5573AABazejkzWyY/D1GZNhcCCxHbh5BEARB9CEsGTZFUfD000/jo48+QiQSAUuIygSDQaxfvx4fffRRyRrJO8FgpGznSp5yKn8NtbzkKuuhBlH14f8DAKh146E1HAwhaiLNbXJSwgicoypvsZBy6kJYgzThE9KFP0gTPrFTF0uG7a677sIjjzyCgw46CC0tLXC5XGhoaMDGjRuhKAouv/zyUreTa/z+sE1nZhBY/i7RXAg5InPuLx+FGG4DAPhP+F8jotaTQQc2Tf5uny5ENkgTPiFd+IM04RM7dbFU1mPZsmW46KKL8Pzzz2PhwoU45JBD8Mwzz+C1117DyJEjoar9u2uqrq7KnhMnGqFY5K1Qc6Rl//A5dr0DAOg68U9QhxxTaOtsH3Rgmy5EVkgTPiFd+IM04RM7dbFk2Nra2nDccccBACZNmoRPPzXmkhw0aBAuvfRSLFu2rHQtrAAcDsmmM+uwNNoz5yG0zHsqAUiB3WCiA+qAyQkrKmeggX26ENkgTfiEdOEP0oRP7NTFkmGrr6+H32+MFBw9ejSam5vR1mZ0lQ0dOhT79u0rXQuJ7CRE0wTzf1aQdTNGkKaYMMYgt28EAOjVIwDRUs95xqMTBEEQBNF7LBm24447Dn/4wx/w1VdfYeTIkWhsbMRjjz0GTdPwyiuvoKGhodTt5BpNs6uQXuqE79EyH0KBTwCJXZdREyi1bQAAaDVjkGS8CvFgNvs1+3QhskGa8Anpwh+kCZ/YqYslw3bttddC0zTceuutEAQBP/nJT/C///u/mDJlCp544glccMEFpW4n17S2Buw5cUq+mtix2VgmWJI1gRRnpUXg2PWu8WdN5c4Za5suRFZIEz4hXfiDNOETO3Wx1NfV1NSE559/3uz6POecczBq1Ch8+umnmDx5Mo4++uiSNpJ3qqqc6O62Y6gvSzJtsbptRoStgNp4gphUkLdq1V1wNK8GAGh141I3LqB9KfOclhn7dCGyQZrwCenCH6QJn9ipiyXDds0112Du3LmYPXu2uWzGjBmYMWNGyRpWSXi9rvIJmJi3ljqvqCDC6BI1ImwZstMykxKRi5k1JldBT+0SrSDKqgthCdKET0gX/iBN+MROXSwZtu7ubvzqV79CKBTCwQcfjLlz52LOnDk4/PDDIXA+AXjfJmFqKsCIrDEGJspRiyVA8w6BFNgNsW0DBDUMrWlK+mFSct50Zw3ESCf8s+/OUJqjgpLYCIIgCKKPYMmwPfDAA1BVFatWrcJ7772H5cuX409/+hNqampw3HHH4fjjj8fpp59e6rYSqaTksDFRMkZ9inEDpg2YAq1uAga8/D0AQOe8pYDkTD5OSoRNUIPGvrVjIEY6UrYlE0YQBEEQ5cZydrosy5g5cyauvfZaPPvss/jLX/6C0aNH48UXX8T1119fyjZyT1ubXYMOUrtEY0YtKmt0ZgKp62tzk5pXF0Letyr5MImGTYtA0BUwUQYkV/w4PcFmc2ebLkRWSBM+IV34gzThEzt1sRRhi0QiWLt2LVatWoVVq1Zh9erV8Pv9GDFiBM466yzKZSsxgq5DOvA5tPqDUtaw5Hx+UTaibmKyD5daPk967V77R/hP+kvCCeIROUExPozM4ctiuCpn0AFBEARB9BUsGbYjjjgCqqpi/PjxmDFjBv7rv/4LRx11FAYOHFjq9lUE9fVeNDd3lez4ov9rCLoKiBJ079CENSnDCgQpuixm2Ix1jn3/ST5gWpdo/BiC2m0c2VENlsmcVVCXaKl1IQqHNOET0oU/SBM+sVMXS4Zt9uzZWLVqFbZv347a2lr4fD7U1dXB5/OhqormOysvifOHMoj+eHdnrGuTicmDCBw7304+QqyrM0ZCl6gZYXP6Mp9ddFhvagWZO4IgCILgGUuG7f777wcAfPnll1i5ciU++ugjPPXUU/D7/Zg0aRKOOuooLFq0qKQNJdIRwm2QArvN12JgLwRdiRsw0QHntmWQW79I2k8Mt6UcKYNhc1RnNlypZo8gCIIgiJJT0CSRkyZNwqRJk/C9730PH3/8MZ544gn8+9//xrp16/q1YQsEwiU6cu7cL0HXkl6LSjRMKzqg1h8E3VWHAX8bDQBQ6yYgMvo0VK25xxgFqgYB2WOcJSHCJnbvBQDonsbEMyX8WcgsCvZG2EqnC9FTSBM+IV34gzThEzt1sTzoYPXq1Vi5ciU+/PBDfPbZZxAEAdOnT8f111+POXPmlLqdXGNfccN0Q+fa8CS06uHoPvbXcGx/1VweGTUP6tBjoa9/BGK4DYLSDRY1bIkmTOzYAgAZBjhUHlR0kj9IEz4hXfiDNOETO3WxZNiOOuooRCIRDB06FLNnz8aPfvQjHH300ZS/FqWhwVui+cVyR6ikzm3JW0c64dr8DwCAOugo1Lx6PgAgMuIbUEacaJTrkD1AuA2CGozbvegoUSHcAefOtwAAWv2kvOfPB7M5h610uhA9hTThE9KFP0gTPrFTF0uG7dprr8Xs2bMxduzYUrenIpGkQidbt0ph5TBi+WcATLMGAOHx340fKxpVE7Rgwo5G++V9H0PQwtC8Q6E2TQN040mCpfguZegsQLcyV6m9hq10uhA9hTThE9KFP0gTPrFTF0uG7YILLoCqqnj++efx4Ycform5GTfeeCNWrVqFQw89FJMmTSp1O4kYLIeJU9JdP5O9CE/6Phw73oi+jnaDKumGLVZgVxlxolHTTc8c+mXOmh40nCAIgiCInmLJKra1teHcc8/FDTfcgHXr1uG9995DIBDA66+/jvnz5+PTTz8tdTu5RlG0/Bv1iGiEKpdJS9w6g2FTmw5PGu3JckTYxM7tAACtemRPGpupRdGT2lM4t3S6ED2FNOET0oU/SBM+sVMXS4btjjvugN/vx2uvvYbnnnsOLHoDvvfeezFlyhQsWbKkpI3knfb27hIducAu0VjR24RaabpnQPIRY4ZNjRs2JogQQm2Q27409qkZ06PW8kbpdCF6CmnCJ6QLf5AmfGKnLpYM21tvvYWrr74aw4YNg5AQrXE6nbjwwguxbt26kjWwEvD5+KhNFouw6b4R5jLd05S8UaxLVE2OsPlWXAPA6EJlrpqUvLXKnEuUF12IOKQJn5Au/EGa8ImdulgybJqmweXK3EhVVc2IW3/F43Hm36hHFGZ4YoZNqx5uLmNJ9dTSI2xCpBPy/k/M15Hhc3vc2gwtKuKxCqd0uhA9hTThE9KFP0gTPrFTF0uDDo4++mj87//+L4488kj4fMaURYIgQFEUPPLIIzjqqKNK2sj+S8+6RHXfcDDRAUFXEB5zevIRJTcAQG75Au6NT6UdI3TYRRBigw1oaimCIAiC4AJLhm3x4sWYP38+TjrpJEydOhWCIOCee+7Bli1b0NnZiccff7zU7SRg1F1Lrb2WiBA8AMDoBu349guAIENrmpq0TWyOULnls7T9w6NPTTBpRTBr5rH6dwSWIAiCIHqLpS7RkSNH4oUXXsD3vvc9dHR0YOTIkThw4ABOOOEE/POf/8S4ceNK3U6uaWnxl/gM+Q2PGNgD5+53AQBazRioQ2dBHTIzbTu9alDG/SPDZiN80ILMB6/QSFvpdSEKhTThE9KFP0gTPrFTF8tziTY2NuKnP/1pxnVtbW2or68vWqMqDVkWEYmUYKhvLDfQQo6gc+vL5t96TfayHHrVYPNvdcDhkA8YJVmUEd8EpGL3zdtr9EqmC9FjSBM+IV34gzThEzt1yRlhi0QiWLFiBVasWIFgMJi2XlVV/O1vf8O8efNK1sBKoLa21FN05TdsQqgFAKB7BiaZsrQjueODEEITz0XnyQ8jMOOm+NyhfWgASel1IQqFNOET0oU/SBM+sVOXrBG2LVu24Ec/+hH27NkDABg6dCgeeughjBhhlIx4++23cccdd2D79u0YNmxYeVrb7zDMk7U4lbFt9+GXQ2s8JPtmooTwuDMhdu+HMvxEaAMOhRBsgWPfRzmO3dNIWWV2pRIEQRAEb2SNsP3ud79DIBDAr371K9x9992QJAm/+c1voCgKFi9ejMsuuwytra247rrrsGzZsnK2uR9hPdolqCFjD3eDOXNBNsIHzUdw2k+M6aeyHpDMFkEQBEHwQtY79urVq3HllVfinHPOAWDksF1yySVYtGgRli1bhrPPPhvXXnttv85di9HVFbK7CWYdNSZ7bW5JAoK9U1PxoAuRDGnCJ6QLf5AmfGKnLlkNW2dnZ9Kk7pMnT0YoFML777+Pv//97zj66KPL0sBKIBRSSnPgQoxOLMLm8PX2pAl/9zbKZm+UrmS6ED2GNOET0oU/SBM+sVOXrH1nmqbB6YyPGozNdLB48WIyayk0NVUX5ThCuB1QEocMF9IlGp1H1FlAhC0WAcvoq4Qsf1cOxdKFKB6kCZ+QLvxBmvCJnbpYqsOWyIQJE0rRDgKAY88HcO56J76ggAiboEUjbHJvP0xF7L6kPDiCIAiCKAoFGzaBbsJlxKJ5YjoELQwGAXDQUHCCIAiC6GvkLJx75513oro6OWJz++23m/OJxhAEAX/84x+L37oKIRxW7W1ANH8NshtMLNiDJ1PUAQKGudd99pR9sV0XIg3ShE9IF/4gTfjETl2yGrbYhO6BQCDnMgLo7EwvKlwcrJknIdJpbO3woXj5ZgnH6WlUVRAQGXkSIEjFaVKBlE4XoqeQJnxCuvAHacInduqS1bAtXbq0nO2oaGpqPKUR0WK0SwzuB2BM+p6vBltmEg1ZkUtw5Kr1VmJKpgvRY0gTPiFd+IM04RM7dell/xkBAC6XfaYEAMRgM4CoYavQEZ2lwG5diHRIEz4hXfiDNOETO3Uhw8Y11qJdjl3vGlvniLCpg2ZAqx4JrXZcnlP2nblECYIgCKKvQBaeZyyYJyHYDLn1CwCAVjs2a74Zc9VCc9UCAET/TghaGDmjcULl12EjCIIgiL4CRdiKQHNzl23nljq/BgBo1aOgDjoCvTdXfSfCZqcuRGZIEz4hXfiDNOETO3Uhw1YE3G5HSY4rWDBPon8HAEBtPMTcizAolS5EzyFN+IR04Q/ShE/s1CVrl+hrr71W0IFOPvnkXjemUqmudpdmfjELXaJiYC+AhFpnlkaJppo6Icua2NRVlWkCS6YL0WNIEz4hXfiDNOETO3XJatiuuuqqpNexGQ5YgolInPVg/fr1eU+maRpuvPFGbN26FZIk4Y477gBjDIsXL4YgCJgwYQJuvvlmiKKIp59+Gk8++SRkWcZll12GE044AaFQCNdffz1aWlrg9Xpx5513oqGhoeCL7ksI0blHmaOm2Ecu8vEIgiAIgugpWQ3bm2++af79xRdf4Oc//zmuuOIKnHzyyRgwYADa29uxfPly3HPPPfjVr35l6WRvvfUWAODJJ5/EypUrTcN29dVXY+bMmfjlL3+JN998E1OnTsXSpUvx7LPPIhwOY8GCBZg1axaeeOIJTJw4EVdeeSVeeukl3H///bjxxht7+RbwjIVBB7FJ3x0e4/8e1WEjCIIgCIJnshq2YcPi0wlddtlluPLKK3HBBReYywYOHIhzzjkHqqrit7/9LU488cS8J/vmN7+J448/HgCwe/duDBgwAG+//TZmzJgBAJgzZw7ee+89iKKIadOmwel0wul0YuTIkfjyyy+xatUq/OhHPzK3vf/++/OeUxQFNDXFp9dqazNmaaiv95rLAoEwursjaGjwQpIMw6MoGtrbu+HzueDxOM1tW1r8kGURtbXxOTu7u8MAkHSecFhFZ2cQNTWepLotzc1dcLsdqK52m8s6OrqhqjpqagzTJTRVIxiMILSPwet1QpKMmQJ0XYffH4bLJcPlivaj68a0VILTZ+w/oBqCrzrnNXk8DjhFAWj0QWisRuuudsiyiKoqV/w9cTkQiRhFAtHgg1BX3aNramyMT2MWDEbg94dRV1cFh8O4Jk3T0doaQFWVE15v/PzF0CkQCCdp0tUVQiik9FonO68p9bNXadcUiahJbe0L19QXdAKM36++dE19Qaempty/5ZV4TX1BJ1kWy3JNqQiM5U+Umjp1Ku69917MmTMnbd3bb7+Na665BqtXr853GJNFixbh9ddfx7333ovFixfj3XeNOmIffPABnn32WcyePRsbN27E9ddfDwD42c9+hjPPPBMPPvggbrrpJowbNw66ruP444/HihUrcp4r9oaVElEUoOu9H13p3LYMABAZfSoAQN77EcRQS859fG9fBbF7H/xzfw/dOwTKwCPAqgbm3Mex4y0IWghq3XjodRMghNvh2PNB0jZq46EQwp2Q/DugNhwCvWZUL67MHoqlC1E8SBM+IV34gzThk3Loks20Weo/O/jgg/Hwww8jEokkLff7/fjTn/6EadOmFdSYO++8E6+++ipuuukmhMNhc3kgEEBNTQ18Pl/SfKWBQADV1dVJy2Pb8kCiSy87sS5ROebUKfcshq26EBkhTfiEdOEP0oRP7NTFUuHcxYsX4wc/+AHmzJmDGTNmoK6uDq2trVi5ciVkWcajjz5q6WT//Oc/sW/fPlxyySXweDwQBAGHHXYYVq5ciZkzZ2LFihU4+uijMWXKFPz+979HOBxGJBLB5s2bMXHiREyfPh3Lly/HlClTsGLFChxxxBG9unj+yePiGYOgpBi2Ch3RSRAEQRBEdiwZtsMPPxwvvvgiHnnkEaxevRobNmxAfX09FixYgAsuuMDySM2TTz4ZP//5z/H9738fqqrihhtuwLhx43DTTTdhyZIlGDt2LObNmwdJkrBw4UIsWLAAjDFcc801cLlcmD9/PhYtWoT58+fD4XDg7rvv7tXFc0++qKsegcA0MNEBSLHaMGTYCIIgCKKvYSmHrZIpRw6bz+eC3x/Ov2EeYjlsat14QHRADOyFGG7Lur0QakP1vy+F7qyF/5sPAgCUwTPA3I05z2Mth+0wCJFOSF1fV2wOW7F0IYoHacInpAt/kCZ8Ug5dsuWwWZ5LdMeOHfjTn/6EDz74AAcOHMATTzyBF154AePHj8c555xTtIZWIsUWT27fBADQXfU5txOD+wEAzJ24XSERNiHl/74F/djxB2nCJ6QLf5AmfGKnLpYGHaxfvx7f+c53sGrVKpx44olQFKPKL2MMv/zlL/HPf/6zlG3knrq6qvwblQCxaycAQPONSFjaN81XT7BLFyI7pAmfkC78QZrwiZ26WIqw3X777Zg6dSoefPBB6LpuDjK44YYboKoq/v73v+PMM88sZTu5JlazpayoIXg+N7pB9erh8eU06MDEFl2InJAmfEK68Adpwid26mIpwrZ27VosXLgQoigmTUcFAPPmzcP27dtL0jgiO/KBz8y/1abp8RVFm+kgUec+neZIEARBENxj6e7u8/nQ3Nyccd2ePXvg8/XvejGappfoyNmNktxiGLbQhHOg14xMWNODCFsfjcqVTheip5AmfEK68Adpwid26mLJsJ1yyilYsmQJPvzwQ3Pyd0EQsHXrVvzhD3/AN77xjZI2kndaWwP5NyoyQtCYAUGvHpG0nPVR89UT7NCFyA1pwiekC3+QJnxipy6Wctiuu+46bNq0CT/4wQ/g8RjzXV588cVobW3FYYcdZk4h1V+pqnKiuzuSf8MiIqjGh4Y5vKlrinmWIh6r/NihC5Eb0oRPSBf+IE34xE5dLBk2j8eDhx9+GO+88w4++ugjtLe3w+fz4YgjjsCJJ54IUSxW3lRl4vW6ym/YzBkOSmTY+kCkzg5diNyQJnxCuvAHacIndupiybD985//xNy5czF79mzMnj07aV1zczNeeOEF/PCHPyxJA/s1OWoaC7E5RFMjbIUYrT5gygiCIAiiP2ApNPbzn/8cO3bsyLhu7dq1+P3vf1/MNhEWEJRol6icWhOGTBhBEARB9DWyRtguuOACfPaZMRKRMYYLLrggraQHAIRCIRx66KGla2EF0NbWsyRE0b8b8oFPERlxIiC5rO/IdEANGn/LnuR1PYqaZdqn8o1fT3UhSgdpwiekC3+QJnxipy5ZDdtNN92EV155BYwx/O///i++9a1vYfDgwUnbiKKImpoanHbaaSVvaF9B9O8Cc1aDOWsgdn0NABAUP1ghhk0NQgADkz2AmFrEr/KNFkEQBEEQyWQ1bOPHj8cVV1wBwCjhcc4552DQoEFla1glUV/vRXNzl6Vt5QNrAQCR0ada2DpzDpuZv5bWHQqUxLDlyKXjmUJ0IcoDacInpAt/kCZ8YqculgYdxIxbMBhEJBIxa7ExxhAKhbB69WqKsvWKwkyWmb+WVtIDNJCAIAiCIPoglgzbV199hcWLF+OLL77Iug0ZtvIRL+mRIcJW0NRUecwdmT+CIAiC4AJLhu2OO+5Ac3MzFi1ahLfeegsOhwMnnngiVqxYgeXLl+Ohhx4qcTP5JhAIl/V88aK5mbpECyfj7Ah9wKyVWxciP6QJn5Au/EGa8ImdulgKx6xZswbXXnstfvCDH+D0009HIBDAggUL8Kc//QmnnXYali5dWup2cg0/RXMBGnQQh4pO8gdpwiekC3+QJnxipy6WDJuqqhg+fDgAYMyYMfjyyy/NdWeeeSY+/fTT0rSuQmhoyGScrJAnmT9Lsn9s0AEyRdj6QGSsWPRcF6JUkCZ8QrrwB2nCJ3bqYsmwjRo1yjRpY8eORTAYxObNmwEAuq7D7/eXroUVgCSVeWquXIMOigTrA5G6sutC5IU04RPShT9IEz6xUxdLOWxnn302fvvb36K7uxsXX3wxpk+fjl/84hc499xz8fDDD2PSpEmlbmcfp9BRornKepT+/ARBEARBlBdLhu2CCy6AqqrYu3cvAODWW2/FZZddhhtuuAFDhw7FHXfcUdJG8o6iaGU9X3we0WIZtr5JuXUh8kOa8Anpwh+kCZ/YqYslwwYgaXL3cePG4dVXX0VraysaGxtL0rBKor29u2c79rAgrRDpNHZ3+Hp23viRerk/3/RYF6JkkCZ8QrrwB2nCJ3bqktWwtbe3591ZkiRzu7q6uiI1qfLw+Vzw+8s31Ffs3g8A0D1NpTtJ0uCFypzpoNy6EPkhTfiEdOEP0oRP7NQlq2E7+uijM072no3169cXpUGViMfjLImAQiajxBjEYDMAQK8aaC5WhhwDIULTmCRSKl2InkOa8Anpwh+kCZ/YqUtWw3b77bcXZNiIXpDtfWZ6+qZKFwQtZEz8nlCHjbnqwFx1JWogQRAEQRB2ktWwnXXWWeVsB6Fk6hdPj7CJ/t0AAL1qUBFrrpExJwiCIAiesTTo4A9/+EPebWITxPdHWlp6WofOMGRi5zZIgT0ZVmcwbJ1bAQBazZgenrMQKtvI9VwXolSQJnxCuvAHacIndupiybA9/PDDacuCwSBUVUVNTQ1GjhzZrw2bLIuIRHo+1FcMd2RZk27YpI5yGbbKNmtA73Uhig9pwiekC3+QJnxipy6WDNvHH3+ccfnq1auxePFiXHrppUVtVKVRW1uF5uaeJ/wzQcpsjzJF2KKROL16eI/P11/orS5E8SFN+IR04Q/ShE/s1KVXcyxMmzYNV155JZYsWVKs9vRPRCnLivRBB2L3PmNN1eDen5cGlRAEQRBERdDrSbGqq6uxc+fOYrSl/xGLoAnZDFsKahBipANMdIC563t+3lSjltG4VX4dNoIgCILoK1jqEl23bl3aMl3XsX//ftxzzz046KCDit6wSqKrK9S7A2QzbCllPSS/YYyNEaI0MXA+eq0LUXRIEz4hXfiDNOETO3WxZNi++93vZqzJxhjDoEGDcM899xS9YZVEKKT0an+WrUs0JYdNal4LANAaDu7V+foLvdWFKD6kCZ+QLvxBmvCJnbpYMmyPPPJI2jJBEODz+XDQQQdBFPt3tKepqbp3SYhZu0RTDFv7JgCA2nhoz89lFUFApY8U7bUuRNEhTfiEdOEP0oRP7NTFkmGbMWNGqdvRz8mcI5ZqlwTF+JAwVy/y1yydiSAIgiAInrBk2MLhMB5++GGsXbsWnZ2daesFQchYq43IjTlXaIbyHRm3VwLG5g5f0VpAEARBEAT/WDJsN954I1588UVMnz4ddXV1JW5S5REOq708glXDZlRYZs5iGba+Te91IYoNacInpAt/kCZ8YqculgzbW2+9hWuvvRYXXXRRqdtTkXR2Bq1tmC2SZiXCxlg8wpYw6TuRHcu6EGWDNOET0oU/SBM+sVMXS6MFqqurMXHixFK3pWKpqfH0an/BQoRNav8KAtPARBmQHL06n9VWmVjssuWN3upCFB/ShE9IF/4gTfjETl0sGbZLLrkE999/P/bu3Vvq9lQkLpelQGV2LBiiqg9vBgAIOoXJrdJrXYiiQ5rwCenCH6QJn9ipi6Uzf+Mb38Df//53nHDCCWhoaIDb7U5aLwgC3njjjZI0sG/DUv7PjsDSp6kqGlmmqNKqR0AM7IbuG1a6cxMEQRAEkRdLhu1nP/sZ9u/fj9NOOw2NjY2lblMfJpsxy2/YdPcAiKEDCI//bvGak28uUUcVlBEnFO98BEEQBEH0CEuG7ZNPPsGvf/1rnH766aVuT0XS6yJ6VnLEdKO6cmTkSQAAZfDRcOz9sHfnzUUfqPhBRSf5gzThE9KFP0gTPrFTF0s5bIMGDYLHQwmQ2XC7Cx8EIEQSRLdg2AS129jUYYwQZZKz4HP2N3qiC1FaSBM+IV34gzThEzt1sWTYLr/8cvz+97/HZ599BlahIwZLSXW1O/9GKTh2vwuoseHBed5TLQJBV4wRoiJ9ia3SE12I0kKa8Anpwh+kCZ/YqYulLtGlS5di165dOPfccyEIQsZBB6tWrSpJA/sy8YEEuQ2bGV2TvfnzznrWEovLCIIgCIKwA0uG7YQTTsAJJ1DyecnIE7WMT0lVlbi0hA0iCIIgCIInLBm2K664otTtqGg6OrqtbZjVmOUxbJEOYytHsWc46Numz7IuRNkgTfiEdOEP0oRP7NTFkmH75z//mXebM888s5dNqVxUtZc10vJE2MTOHQAA3Uv10Aqh17oQRYc04RPShT9IEz6xUxdLhm3x4sUZlwuCAKfTiaqqqn5t2Bobfb0a6ptvaiqpazsAQK8Z1eNz5GtBX6S3uhDFhzThE9KFP0gTPrFTF0uG7eOPP05b1t3djY8//hhLlizBXXfdVfSG9S/yGLZOw7BpJTNsmeibJo4gCIIgKhFLhq26ujrjstNPPx3BYBC//vWv8dxzzxW9cX2PzMYsNqgg8y46xK6vAQBa9eiMm6j1E3vbMIIgCIIgOMZSHbZcDBs2DJs2bSpGWyqWYDBSsmOLHVsg6BHo7kbA6YuvSCjvQbltmSmlLkTPIE34hHThD9KET+zUxVKErb29PW2ZruvYv38//vjHP2LkyJHFbldF4feHS3Zs1+Z/AgDUpqklO0dGSlLvrbyUUheiZ5AmfEK68Adpwid26mLJsB199NEQMtzAGWNwuVy45557it6wSqKurgrt7aUZ6iu1G9HLyJgc87j2AXNVCkqpC9EzSBM+IV34gzThEzt1sWTYbr/99jTDJggCfD4fZs6cmTHHrT/hcEjWNixwWi8h0gkx3AYmuaB7B/egZXnPEP2vbxo+y7oQZYM04RPShT9IEz6xUxdLhu2ss84CYwxbtmzBuHHjAAAtLS3YsGEDvN5iF3MlYsQHG4wAhF6nGxIEQRAEUaFYcgF79uzBt7/9bVxyySXmsnXr1uHCCy/EggUL0NraWrIGVgKaVppCelKnYdj06nKW84hR+VG3UulC9BzShE9IF/4gTfjETl0sGbY77rgDjDH84Q9/MJfNmTMHL730EgKBAH7729+WrIGVQGtrjrIcvSAeYcs0qEPI8jcRo1S6ED2HNOET0oU/SBM+sVMXS4Zt5cqVuO666zBp0qSk5ePGjcNPfvITLF++vCSNqxSqqpzFPyhjkNo2ACjlDAd9m5LoQvQK0oRPSBf+IE34xE5dLCdGBYPBjMt1XUck0r/rxXi9LotbWh90IPp3Qgrshu6ohlZX6sK4GSJ0fWAggnVdiHJBmvAJ6cIfpAmf2KmLJcN29NFH47777sPu3buTlu/Zswd/+MMfcOyxx5akcf0ZqWUdAEBtOhwQSzQqpQ+YMoIgCILoD1gaJbpo0SLMnz8fJ598MiZMmICGhga0tbVh48aNGDBgQNbJ4YmeI0e7Q7X6SXm2BCiHjSAIgiD6NpYM29ChQ/HSSy/h2WefxZo1a9DR0YHhw4fj29/+Nr773e9arsOmKApuuOEG7Nq1C5FIBJdddhnGjx+PxYsXQxAETJgwATfffDNEUcTTTz+NJ598ErIs47LLLsMJJ5yAUCiE66+/Hi0tLfB6vbjzzjvR0NDQqzegGLS1FT8JUfTvBABotWOKfuz+Qil0IXoHacInpAt/kCZ8YqculgwbAHi9Xhx33HG44IILAPSsDtsLL7yAuro63HXXXWhra8N3vvMdTJo0CVdffTVmzpyJX/7yl3jzzTcxdepULF26FM8++yzC4TAWLFiAWbNm4YknnsDEiRNx5ZVX4qWXXsL999+PG2+8sfCrtg3rOWxCyCiVwjwDStUYgiAIgiAqBMt12M4444xe12E75ZRT8JOf/MR8LUkS1q1bhxkzZgAwSoW8//77WLt2LaZNmwan04nq6mqMHDkSX375JVatWoXZs2eb237wwQeWL7SU1NcXuXiwFoGo+MEECcxZU9xjZyJjLlvld7MWXRei15AmfEK68Adpwid26mIpwnbHHXcAQMY6bFdffTV++9vf4je/+U3e48SicX6/H1dddRWuvvpq3Hnnnea0V16vF11dXfD7/UndrF6vF36/P2l5bNt8iKKApqb4sWLhzMQ3PRAIo7s7goYGLyTJ8LCKoqG9vRs+nwseT3wYb0uLH7Isora2Ku1ciecJh1V0dgZRU+OBy2W8zUx1onOHMbVF4jG7u8PQNB3V1R5jQVe7sb2rHl6fG5JkDDrQdR1+fxgul4yaphqg09i+XRYBSbR8TR6PA04BQKMPQk01Wg50QpZFVFXFR7/43Q6E9PzXBADNzV1wux2ornabyzo6uqGqOhobfeayYDACvz+Muroqc3oPTdPR2hpAVZUzafRNMXRK1aSrK4RQSKnoa0r97FXaNaVq0heuqS/oBBi69KVr6gs6NTVV97lr6gs6ybJYlmtKRWAs/wSXM2fOxJ133onjjz8+bd0bb7yBm266yXK0a8+ePfjxj3+MBQsW4Oyzz8acOXOwYsUK81jvv/8+Zs2ahXfeeQe33HILAODHP/4xLr30UjzwwAO4+OKLMWXKFHR1dWH+/Pl48cUXc54v8UZRKpqaqtHcnN88QgvDuePfeTeTWr+A98P/B7VuIrqPvTXjNpERJ5rHiow8CRAt927DsfNtCGoQ6oDDofuGAkyHc/urSdsoQ48Dc1b2HLGWdSHKBmnCJ6QLf5AmfFIOXbKZtrLWYTtw4AAuvPBCXH/99Tj77LMBAIcccghWrlwJAFixYgWOPPJITJkyBatWrUI4HEZXVxc2b96MiRMnYvr06WaR3hUrVuCII46w2vySEgiErW1ocfJ3IdxpbO6q7WmTeg3rAyU/LOtClA3ShE9IF/4gTfjETl0shWViddgOP/xwDB061FxeaB22P/3pT+js7MT999+P+++/HwDwi1/8ArfddhuWLFmCsWPHYt68eZAkCQsXLsSCBQvAGMM111wDl8uF+fPnmyVGHA4H7r777h5ccvHp7i5u4WBBMdx7pUe47KbYuhC9hzThE9KFP0gTPrFTF0tdort378b8+fPR0tKSsQ7bY489hmHDhpWjvQVTji7RhgavtfnF1BCcO9/Ku5lz03Nwb3wK4bH/hfCkBRm3KXWXaGTYbMDhy3KEysCyLkTZIE34hHThD9KET8qhS7Yu0bLWYeurxBIMi4UQMRLmmdOqYept92Xld39moti6EL2HNOET0oU/SBM+sVMXy2EZn8+HCy64wKzDFmPPnj14+OGHccUVVxS9cf0JBgFCtE6b2SXqyGWES22y+qaJIwiCIIhKxHo/WgKqquLNN9/EM888gw8++AC6rvdrw6YomsUtc/Q+O7yAYkTW4hG2/h257C3WdSHKBWnCJ6QLf5AmfGKnLgUZti1btuCZZ57B888/j7a2NjQ2NuL73/8+zjjjjFK1ryIodo6cGImOEq3wHDK7KXXuIlE4pAmfkC78QZrwiZ265DVsoVAIy5YtwzPPPIPVq1fD7XYjFArhpptuwnnnnQdRpH52n88Fv79IQ30Zg9i9BwCgVw20tk9vS3D0gRIemSiqLkRRIE34hHThD9KET+zUJavb+vzzz3HzzTdj1qxZ+MUvfgGPx4M777wTr7zyChhjmDBhApm1KIkVjHsKi+aMuTY+CUExRqAwV32vj5uTnEat8k1cMXQhigtpwiekC3+QJnxipy5ZI2xnn302JkyYgKuuugqnnnoqBg40oj1WpoMismChcK5r8z/jL/po5IsgCIIgiMLIGiI76KCDsGnTJjz//PN47LHHsHnz5nK2q98THvedPFuQmSMIgiCI/kLWCNvzzz+PjRs34h//+Aeee+45PPjggzj44INx8sknQxAEc8J2Ij7ReK9hDEyQIDAN4fFnFeeY/Zii6UIUDdKET0gX/iBN+MROXXImoU2cOBGLFi3C8uXL8cADD2DMmDF44IEHwBjDXXfdhccffxwHDhwoV1u5RZaLkMsnCIAWhsA0MMkFSIX0k5fAPPcBQ14UXYiiQprwCenCH6QJn9ipi6Uzi6KIOXPm4O6778a7776L2267DU6nE7feeivmzp2LhQsXlrqdXFNbW2Vxy9w5bEK0Dlvpy3lUvhmzgnVdiHJBmvAJ6cIfpAmf2KlLwYVzvV4vzj77bJx99tnYs2cP/vGPf+Bf//pXKdrW74gbNm9Zzsf6iXEjCIIgiEqnV7G9IUOG4PLLL8eyZcuK1Z5+jAAxsBcALwVzycwRBEEQBC9QJ3kR6OoK9foYUtsGVK3+HwCA7m4obOc+kG9WCoqhC1FcSBM+IV34gzThEzt1IcNWBEIhpdfHcH79hvm3OuTYXh+PKI4uRHEhTfiEdOEP0oRP7NSFDFsRaGrq/STtcus6AIAy6EiER5+WfweKquWlGLoQxYU04RPShT9IEz6xU5esgw7WrVtX0IEOPfTQXjem75N9lKgQ7gAAhA75/wCa8osgCIIgiASyGrbvfve7WYvjMsbS1q1fv764LetnmPOHlmmEqHHSHFE6iuARBEEQBDdkNWyPPPKI+ffOnTtxyy234Nxzz8W8efMwYMAAtLe34+2338bjjz+Om2++uSyN5ZVwWO3dAXQVghYyymxIbtAIzeLQa12IokOa8Anpwh+kCZ/YqUtWwzZjxgzz7//5n//BRRddhCuvvDJpm2nTpsHr9eKvf/0rTj/99NK1knM6O4O92l9Qo/s7qiiyVUR6qwtRfEgTPiFd+IM04RM7dbGULPXFF19g2rRpGddNmjQJW7duLWqjKo2aGo+l7QSWJYct1h0qRysoc2HaeGhD77CqC1E+SBM+IV34gzThEzt1sWTYxo4di3/84x9py3Vdx+OPP45JkyYVvWGVhMtV8IQRSQhqN4BC89cq31CVmt7qQhQf0oRPSBf+IE34xE5dLJ356quvxuWXX44NGzZg9uzZqK+vR0tLC9566y3s378ff/vb30rdzj6NoEQNWyzCRmaMIAiCIIgELBm2uXPn4rHHHsNf/vIXvPDCC+jo6EBdXR1mzpyJyy67DOPHjy91O/s08QgbTfZLEARBEEQ6lmN7U6dOxR/+8IdStqViaW7usrhl5hw2IdJprHXwVCix8qN81nUhygVpwiekC3+QJnxipy6WK7R2dXXh/vvvx8KFC3Hqqafiq6++woMPPogVK1aUsn0Vgdvt6NX+QrgdAMBcdbElvTpeAWcu03nsobe6EMWHNOET0oU/SBM+sVMXS4Zt586dOOOMM/DQQw/B5/Nh27ZtiEQi2LBhAy677DIsX7681O3kmupqd6/2F6OGTXfVpq3LPjcCkY/e6kIUH9KET0gX/iBN+MROXSx1if76179GU1MTHnroIbhcLhx22GEAgLvvvhuqquL+++/H3LlzS9rQvkxahI2Lsh4EQRAEQfCCpQjbhx9+iEsuuQRerzdtSqrzzjsPGzduLEnj+gVqCI59HwNI7BJNJIt5K7WpI9NIEARBENxgybA5nU6Ew+GM69rb2+F0OovaqEqjo6Pb2oYZCufK+1eZf+tVg4rVJAIF6EKUDdKET0gX/iBN+MROXSwZtrlz5+L3v/89tm3bZi4TBAHt7e148MEHcdxxx5WqfRWBquo93lcMtRnHqJsA5m6ILqXoVjHojS5EaSBN+IR04Q/ShE/s1MWSYVu8eDGcTidOP/10fPvb3wYA/OIXv8BJJ52Erq4u/OxnPytpI3mnsdHX430FxQ8AUIYcm7BQyPx30enbxrA3uhClgTThE9KFP0gTPrFTF0uDDhoaGvDcc8/hH//4Bz766CMMGjQIPp8PZ555Jr773e/C56MPVk8RIkZNF5ZhhKi99G0zRxAEQRCVhOXCuS6XC+eddx7OO++8Uranj5OewyYoUcPmrCl3YwiCIAiCqBAsGbZcMxyIooiqqiqMGjUKs2bN6pcDEILBSI/3NSNszsRZDoQsfxOF0BtdiNJAmvAJ6cIfpAmf2KmLJcP2wgsvYO/evYhEIpBlGXV1dWhvb4eqqhAEASw6+nHs2LF4+OGH0dTUVNJG84bfn3kErRViOWzcRdj6QFmP3uhClAbShE9IF/4gTfjETl0sDTq44oor4PF4cO+992Lt2rV499138dlnn+FPf/oTGhsbsWTJEixbtgxOpxO/+93vSt1m7qir6/mk7bEIm+5MzGGzMuig8g1VqemNLkRpIE34hHThD9KET+zUxZJhu++++/DTn/4UJ598MkTR2EUQBBx//PG45ppr8D//8z8YM2YMLrnkErz77rslbTCPOByStQ1T67AxFo+w2THooA9E0XJhWReibJAmfEK68Adpwid26mLJsB04cACDBmUu6trY2Ij9+/cDAJqamhAIBIrXur6OFoagK2CiE5BcdreGIAiCIAhOsWTYJk+ejD/96U/w+/1JywOBAP785z/j0EMPBQB89tlnGDZsWPFbyTma1rNCevERotUpK2jQQTHoqS5E6SBN+IR04Q/ShE/s1MXSoIMbbrgBF1xwAU488UTMmDEDDQ0NaG1txUcffQRBEPD3v/8dH3zwAe6+++5+WUS3tbVnUcXMI0R5ofKNYk91IUoHacInpAt/kCZ8YqculiJskyZNwssvv4z58+ejpaUFH330ETo7O7Fw4UK8+uqrOOSQQ+DxeHD77bfj/PPPL3WbuaOqymopk+QcNiESzV9zpBYepghbMbCuC1EuSBM+IV34gzThEzt1sVw4t7GxEddcc03W9VOnTsXUqVOL0aaKw+t1obu78NosWbtELe1MRi4fPdWFKB2kCZ+QLvxBmvCJnbpYNmwbN27Exx9/DEVRzLprjDEEg0GsWbMGf/7zn0vWyL6CY+/KpNdml2hKhI3x4MXIEBIEQRAEN1gybE899RRuueUW06glIooijj322Ax7EfmwNC0VGSeCIAiC6PdYymH7+9//juOPPx4rV67Ej370I5xzzjlYs2YN7r33Xng8Hpx++umlbifXtLUVnoQodu2AY+/HAPLlsJWSvm0Ge6ILUVpIEz4hXfiDNOETO3WxZNh27tyJBQsWoLa2FpMnT8bHH38Mt9uNk08+GZdffjkeeeSRUrezz+F75zpIXdsB8DpKlCAIgiAIXrBk2DweD2TZ6D0dNWoUduzYgVAoBACYMmUKtm/fXroWVgD19d7CdkjpWk6PsCXSt6NgpaRgXYiSQ5rwCenCH6QJn9ipiyXDNm3aNDzzzDPQdR1jx46FLMtYsWIFAGMwgstFVfoLQg0mvdRzFc61IYctPVORIAiCIAg7sTz5+1tvvYWLLroITqcT5557LhYtWoSFCxfiN7/5Db75zW+Wup19CiHSmfQ656ADgiAIgiD6PZZGiU6ZMgUvv/wyvvrqKwDAz3/+c9TW1uLTTz/FRRddhIsvvrikjeSdQCBc0PZigmELHvIDsKqBKVtQN2gxKFQXovSQJnxCuvAHacIndupiybD99re/xWmnnYY5c+YAMEp5XHHFFSVtWCVRaBG9WP01pWkqlNGn5tu6h62y0hAbzllGqOgkf5AmfEK68Adpwid26mKpS/Spp55CZ2dn/g37KQ0NhSUhxrpEs3eF9g3DZDeF6kKUHtKET0gX/iBN+MROXSwZtqlTp+L111+Hpmmlbk9FIkmW3kaT/IaNKAaF6kKUHtKET0gX/iBN+MROXSx1iQ4bNgzPPPMMXn75ZYwaNQoNDQ1J6wVBwB//+MeSNLDPkFDKw5ySykr9NZrpgCAIgiD6PZYM29atWzFt2jTzdSBAFZgTUZTCIo8UYSsPhepClB7ShE9IF/4gTfjETl0sGbalS5eWuh0VTXt7d0Hb542wJUXVbIiw9ZGoXqG6EKWHNOET0oU/SBM+sVMXS4Ytxn/+8x98+OGHaG5uxiWXXIKvvvoKBx98MAYOTC1L0b/w+Vzw+/MN9U3oElUyRNj6iEniCWu6EOWENOET0oU/SBM+sVMXS9lzoVAIl156Kf77v/8bDz30EJ5++mm0tbXhoYcewplnnonNmzeXup1c4/E4C9pejEXYHHbPIdq3TWKhuhClhzThE9KFP0gTPrFTF0uG7Xe/+x3Wrl2Lxx57DB9++CFYNIH+rrvuwqBBg3D33XeXtJF9CsYghNoAALqrLstGcSPFcpgqZcixUAZOL2Lj0s9PEARBEIT9WDJsL730Eq677jocccQREBK67gYMGIDLL78cq1atKlkD+wxRkytEOiDoEegOH+Co6t0hXbVgVYOK0TqCIAiCIDjGkmELBoNobGzMuM7lciES6d8VmVta/Ja3Fbv3AwCYp3/n/ZWDQnQhygNpwiekC3+QJnxipy6WDNvhhx+ORx55BKqqmstikbZnn30WkydPLk3rKgRZtvI2RiNs3fsAAHpVU/ZNEwcg0GCEHmNNF6KckCZ8QrrwB2nCJ3bqYmmU6PXXX4+FCxfi1FNPxaxZsyAIAh5//HFs2bIFn3/+OR5++OFSt5Nramur0NzcZWlbMRzNX3MPKGWTekcfMYmF6EKUB9KET0gX/iBN+MROXSxZxcMOOwzPPPMMJk+ejDfeeAOSJOGNN95AfX09nnjiiaSiuvn49NNPsXDhQgDA9u3bMX/+fCxYsAA333wzdF0HADz99NM466yzcO655+Ktt94CYIxUvfLKK7FgwQJcdNFFaG1tLfRa7cXMYStgloMyojRNgzLwCLubQRAEQRBEBixF2ILBIMaPH48lS5b06mR//vOf8cILL8Dj8QAA7rjjDlx99dWYOXMmfvnLX+LNN9/E1KlTsXTpUjz77LMIh8NYsGABZs2ahSeeeAITJ07ElVdeiZdeegn3338/brzxxl61xw7iho2vWQ6YdzCg9e9cRIIgCILgFUsRtmOOOQY//elP8e9//xuKovT4ZCNHjsR9991nvl63bh1mzJgBAJgzZw7ef/99rF27FtOmTYPT6UR1dTVGjhyJL7/8EqtWrcLs2bPNbT/44IMet6PYdHWFLG/LV4Stb3R9ZqMQXYjyQJrwCenCH6QJn9ipi6UI23XXXYdXXnkFV1xxBaqrq3HSSSfh9NNPx8yZM5PKfORj3rx52Llzp/maMWbu7/V60dXVBb/fj+rquJnxer3w+/1Jy2PbWkEUBTQ1xY/X1mbMg1pf7zWXBQJhdHdH0NDghSQZHlZRNLS3d8PncyUVymtp8UOWRdTWxktyxARMPE84rKKzM4iaGg9cLhlMiwAdHqjReUSr6puAKacA25ajuzsMRRBQU2NEHtHgQyQgIxRS4fO5IauGSdZ1HX5/GC6XjNpeXJPH44BT8AADqiF4qs1rqvHVAB0eQHLC73YgFFJyXlOM5uYuuN0OVFe7zWUdHd1QVR2NjT5zWTAYgd8fRl1dFRwOCQCgaTpaWwOoqnLC63UVVSdd15Pa39UVqvhryvTZq6RrkmUxqa194Zr6ik7V1e4+d02VrlN1tbvPXVNf0ElVtbJcUyoCi1XBtUBzczOWLVuGV155BatXr8aAAQNw2mmn4Vvf+hamTJli6Rg7d+7Etddei6effhpz5szBihUrAABvvPEG3n//fcyaNQvvvPMObrnlFgDAj3/8Y1x66aV44IEHcPHFF2PKlCno6urC/Pnz8eKLL+Y9X+wNKyVNTdUZkxCF7n2QOrZBHTIT0CLwrP0jvB/cBADo/OZfERn/HTi/fh0AoHsGQAweAACojYdCbllnLHfWQox0pB07MvrUHrfXsXM5BLUbyuCjwdz18RWaAueON8BEB5SR3+zx8Xkhmy6EfZAmfEK68Adpwifl0CWbaStofGpTUxPOP/98PP7443j77bfxzW9+E48++ii+973v9ahRhxxyCFauXAkAWLFiBY488khMmTIFq1atQjgcRldXFzZv3oyJEydi+vTpWL58ubntEUfwnyDv2P8JxHBscASDdOBTcx1zN9jTKIIgCIIgKo6CJn8HgLVr12LZsmV47bXXsGvXLhx22GE4/fTTe3TyRYsW4aabbsKSJUswduxYzJs3D5IkYeHChViwYAEYY7jmmmvgcrkwf/58LFq0CPPnz4fD4ais6bBiI0RVY8JYrXY8mNOH5Byyvp1PRhAEQRBEz7Fk2D799FO88sorePXVV7Fnzx6MHj0a3/nOd3DGGWdg1KhRBZ1w+PDhePrppwEAY8aMwaOPPpq2zbnnnotzzz03aZnH48G9995b0LnKRTis5t5A7QYECYJiVEiOjDyxDK3qAWY+Yt8wj3l1IcoOacInpAt/kCZ8Yqculgzb9773PQwePBinnnoqzjjjDBxyyCHmuj179uDZZ5/FFVdcUbJG8k5nZzDneueuFYgMP940bMyRGl3LQSmL2PaRArnZyKcLUX5IEz4hXfiDNOETO3WxZNgeeeQRs/wGAKiqijfffBPPPPMMPvjgA+i63q8NW02NJ7+ITE8xbESpsaQLUVZIEz4hXfiDNOETO3WxZNhiZm3Lli145pln8Pzzz6OtrQ2NjY34/ve/jzPOOKOkjeSdxCHEuRAUY3gz94atj0TerOpClA/ShE9IF/4gTfjETl3ynjkUCmHZsmV45plnsHr1arjdboRCIdx0000477zzIIo0Qa0VxMAeSF1fA0gwbNwZI97aQxAEQRAEkMOwff7553jmmWfw4osvIhgM4phjjsGdd96JmTNnYu7cuZgwYQKZtQJwffWs+Tdz1nBo1giCIAiC4JWshu3ss8/GhAkTcNVVV+HUU0/FwIEDAcDyDAP9CStF9MTgPgBAePSpgOTIszWV+ygGVHSSP0gTPiFd+IM04RM7dckaIjvooIOwadMmPP/883jsscewefPmcraronC78xkwmLMY6LVjLRzR8uQTvSTFDPaxqJ8VXYjyQprwCenCH6QJn9ipS9YI2/PPP4+NGzfiH//4B5577jk8+OCDOPjgg3HyySdDEISC5hDt61RXuxEKKTm3EWKGzVkTW1LiVvUGnttmHSu6EOWFNOET0oU/SBM+sVOXnEloEydOxKJFi7B8+XI88MADGDNmDB544AEwxnDXXXfh8ccfx4EDB8rV1oomFmFjzloLW/cNw0QQBEEQRHGwNGpAFEXMmTMHd999N959913cdtttcDqduPXWWzF37lwsXLiw1O2seMRQCwCAuRINGxkzgiAIgiDyU3BBEa/Xi7PPPhtnn3029uzZg3/84x/417/+VYq2VQwdHd25N2A6hJAxCTwzu0R5JGog+0h3d15diLJDmvAJ6cIfpAmf2KlLr+pyDBkyBJdffjmWLVtWrPZUJKqq51wvKH4ITAOTvYAY88g2mqI+YsjykU8XovyQJnxCuvAHacIndupChdSKQENkI5zbsptWIdwJANBdVvLXykgfN26NjZzPKNEPIU34hHThD9KET+zUhQxbMejclXO1EOkAkKE7VKB6awRBEARB5IcMWxkQIkaEjfUowlZGI2caSDKPBEEQBMETZNiKQCSSpwZbuB1ASoStj3dH8kAwGLG7CUQKpAmfkC78QZrwiZ26kGErAqGQmnO9GDVsuquu9I0hTPz+sN1NIFIgTfiEdOEP0oRP7NSFDFsR8HqdOdcLsRps7sZyNIeIUldXZXcTiBRIEz4hXfiDNOETO3Uhw1YEJEnKuV4MGoZNTzBsjNM8sXLNYloOHI7cuhDlhzThE9KFP0gTPrFTFzJsZcAsmutpsLklFqH8OoIgCILgCjJsRUDXcxTSY7o5LZXeky7Rknqnvm3MNI0KT/IGacInpAt/kCZ8YqcuZNiKQMYkRGZ0LgqhVgi6At3dAMie+HqKYpWc1taA3U0gUiBN+IR04Q/ShE/s1IUMWxFwuTJNyWoYNjGwFwCgVY8qY4t6g4C+Enmrqso9GIQoP6QJn5Au/EGa8ImdupBhKwIul8P4gyWk7Ef/9n50KwBAr6kUw9Z38HpddjeBSIE04RPShT9IEz6xUxcybCWDAVq8qzQy9Dgb20IQBEEQRCVDhq2oJEfYYlNS6a56KCNO7OExy989yWvJEYIgCILor5BhKwJ+f8j4gyVXMRPCueYQtd8UsUwDH/rQYIi2Nkra5Q3ShE9IF/4gTfjETl3IsBUVlvS3GJv03VkDgfWlkrQEQRAEQZQTMmxFwOdzZ1ia0CXqrEHfmkOgMqiv99rdBCIF0oRPSBf+IE34xE5dyLAVE5Y5h405a9K6S/nteuS1XQRBEATRfyHDVlSSu0T1qoFgEKDVTUBFRdi4NZMEQRAE0T/JVPGVKJBwWElfyBjUwTPRdfLfozMcVJBh6yMEAhlmoCBshTThE9KFP0gTPrFTF4qwFYFwWI3+lRxhAxCfjipt0IHFKBZFu3pMd3fE7iYQKZAmfEK68Adpwid26kKGrQj4fNHKxzlHguaJsPFizHhpRxFoaKCkXd4gTfiEdOEP0oRP7NSFDFsREMVMb2OKQauosh59w7RJEn28eYM04RPShT9IEz6xUxf6RBSVuClLr7tWSYaNIAiCIAieIMNWBDRNM/5gGXLYzJd6yl59I4rFM4qi2d0EIgXShE9IF/4gTfjETl3IsBWBQCCWhJhchy2ZSomwCX0mj629vdvuJhApkCZ8QrrwB2nCJ3bqQoatCLjdmaqjVHIOW9/AHAxCcANpwiekC3+QJnxipy5k2IqA0+mI/pU9wib0OMJWumhXX5/f1ONx2t0EIgXShE9IF/4gTfjETl3IsBURIWcOWyVNTcVr2wiCIAiif0KGragUUoetMFPUt2NhBEEQBEHkggxbEejqCmZYmmfQAbcRtr5DS4vf7iYQKZAmfEK68Adpwid26kKGrQiYhfQSuz3T/FrqAnrrS40s03vMG6QJn5Au/EGa8ImdutAnoghUVcVGjeTIYYu+1p21xkteI2y8tqsH1NZW2d0EIgXShE9IF/4gTfjETl3IsBUTlqMOW/Qli00GnzOHLWGdYIdEfce0EQRBEERfgAxbycgcYYuV92ApkSyWxSRlW04QBEEQRP+BDFsRCAYzzHSQbWqqWOTNatejGWEj41YoXV0hu5tApECa8Anpwh+kCZ/YqQsZtiIQn1vMSlmP2P+FGrZy0XeMYSik2N0EIgXShE9IF/4gTfjETl3IsBWBmppoXhoDhFALpLaNGXLYeliHzY4ctj7i2Zqaqu1uApECacInpAt/kCZ8YqcuZNiKjGPvR5A6NqdNRSWkRtisGjFbBh0QBEEQBMET5AaKSo5RouYw0QJz2Mod7upDZT0IgiAIoq9Ahq23MD2ew5ZU1kNL2S5PDpsoZz4+lfXoMeGwancTiBRIEz4hXfiDNOETO3Uhw9ZLpPZNCaNEE9BTRWVJ/6WaIq1+Usbjp5b/IKzT2ZlpyjDCTkgTPiFd+IM04RM7dSHD1lt0BR6PEwAghlriy/NF2FIjZ5IDmm9YhhOQYesp5mAQghtIEz4hXfiDNOETO3Uhw9ZbBBkOhwQAkDq3xhfH6q6Z9HDy99h2ZYu09R2D6HJl6WYmbIM04RPShT9IEz6xUxcybL2EiVKWFbkjbDSDAUEQBEEQViHD1luELIYtLYctdaYDjt96ypsjCIIgCK7g2DVUCKKcOQkxNcKmp86GQKao1DQ3d9ndBCIF0oRPSBf+IE34xE5dyLD1FjGew5aIFNiT9FrocR22+BHKQh+KrrndDrubQKRAmvAJ6cIfpAmf2KkLGbZewgTZHCUKAEzMLaaQK8KWVmzXLvqGaauudtvdBCIF0oRPSBf+IE34xE5dyLD1ltRBB3kMW7ysR98wRQRBEARBlB4ybL2EOWuSX0vOLFvGNsgRYctk4koSdSOzSBAEQRCVBBm23iLK6BxwbOH7lc2cFUrfMXMdHd12N4FIgTThE9KFP0gTPrFTl4qrzKfrOm655RZs2LABTqcTt912G0aNGmVrm1SVxd9IXcu1KbLOdMAVfcO0qWpq8WLCbkgTPiFd+IM04RM7deHZNWTkjTfeQCQSwVNPPYWf/vSn+M1vfmN3k9DQ6DP/FlieiWFzdYkSRaUxQReCD0gTPiFd+IM04RM7dak4w7Zq1SrMnj0bADB16lR8/vnnNrcISdEy3dOUdTMGQK8aaPydkOvGJGPUCXPXG/87vPF1zlrjuL7hRWuu7hmQ1gbzfKIzfx4eQRAEQRBlpeK6RP1+P3y+uMOVJAmqqkKWM1+KKApoaqo2X7e1BQAA9fVxUxQIhNHdHUFDgxeSZJgvRdHQ3t4Nn8+VVLajpcUPWRZRW1uVdJ7IsLkY0FQNyG5APRyRYAid/jBqan1wetxAuBOQnDjQrsMx8CA0NUTNWcOZ6OwMQdQFNI49FGzEGAiOKgTrG+H3h1HXWAt56GAIjipooUPR2qGgyiOjtqbn1+QZcTjcjskQHJ60a2INcwBBhD+gIhRSkt67cFhFZ2cQNTWepPnUmpu74HY7koY7d3R0Q1X1pKeRYDBiXFNdlVm7TtN0tLYGUFXlhNfrKqpOAJLa39UVqvhrSv3sVdo1pWrSF66pL+gEGLr0pWvqCzo1NVX3uWvqCzrJsliWa0pFYIyLTHfL3HHHHTj88MNx2mmnAQDmzJmDFStWZN0+8UZRKnw+F/z+cEnPQRQO6cIfpAmfkC78QZrwSTl0yWbaKq5LdPr06aZBW7NmDSZOnGhzi0BfKk4hXfiDNOET0oU/SBM+sVOXijNsJ510EpxOJ8477zzccccd+PnPf253k1BXV5V/I6LskC78QZrwCenCH6QJn9ipS8XlsImiiF/96ld2NyOJTHOJEvZDuvAHacInpAt/kCZ8YqcuFRdhIwiCIAiC6G+QYSsCmkYFDnmEdOEP0oRPSBf+IE34xE5dKm6UaKGUY5QoQRAEQRBEMegzo0R5pKqKCs3yCOnCH6QJn5Au/EGa8ImdupBhKwKJBfUIfiBd+IM04RPShT9IEz6xUxcybARBEARBEJxDho0gCIIgCIJzaNBBEZBlEapKI3p4g3ThD9KET0gX/iBN+KQcutCgA4IgCIIgiAqFDFsRqK/32t0EIgOkC3+QJnxCuvAHacIndupCho0gCIIgCIJzyLARBEEQBEFwTp8fdEAQBEEQBFHpUISNIAiCIAiCc8iwEQRBEARBcA4ZNoIgCIIgCM4hw0YQBEEQBME5ZNgIgiAIgiA4hwwbQRAEQRAE55BhIwiCIAiC4BzZ7gZUMrqu45ZbbsGGDRvgdDpx2223YdSoUXY3q9+gKApuuOEG7Nq1C5FIBJdddhnGjx+PxYsXQxAETJgwATfffDNEUcTTTz+NJ598ErIs47LLLsMJJ5xgd/P7NC0tLTjrrLPwt7/9DbIskyYc8MADD+Df//43FEXB/PnzMWPGDNLFRhRFweLFi7Fr1y6Ioohbb72Vvis28+mnn+J3v/sdli5diu3bt1vWIhQK4frrr0dLSwu8Xi/uvPNONDQ0FL+BjOgxr776Klu0aBFjjLHVq1ezSy+91OYW9S/+7//+j912222MMcZaW1vZ3Llz2SWXXMI+/PBDxhhjN910E3vttdfY/v372emnn87C4TDr7Ow0/yZKQyQSYZdffjk7+eST2aZNm0gTDvjwww/ZJZdcwjRNY36/n917772ki828/vrr7KqrrmKMMfbuu++yK664gjSxkQcffJCdfvrp7JxzzmGMsYK0+Nvf/sbuvfdexhhjL774Irv11ltL0kbqEu0Fq1atwuzZswEAU6dOxeeff25zi/oXp5xyCn7yk5+YryVJwrp16zBjxgwAwJw5c/D+++9j7dq1mDZtGpxOJ6qrqzFy5Eh8+eWXdjW7z3PnnXfivPPOw8CBAwGANOGAd999FxMnTsSPf/xjXHrppTj++ONJF5sZM2YMNE2Druvw+/2QZZk0sZGRI0fivvvuM18XokWiF5gzZw4++OCDkrSRDFsv8Pv98Pl85mtJkqCqqo0t6l94vV74fD74/X5cddVVuPrqq8EYgyAI5vquri74/X5UV1cn7ef3++1qdp/mueeeQ0NDg/njBYA04YC2tjZ8/vnnuOeee/D//t//w3XXXUe62ExVVRV27dqFU089FTfddBMWLlxImtjIvHnzIMvxLLFCtEhcHtu2FFAOWy/w+XwIBALma13XkwQnSs+ePXvw4x//GAsWLMAZZ5yBu+66y1wXCARQU1OTplMgEEj60hHF49lnn4UgCPjggw+wfv16LFq0CK2treZ60sQe6urqMHbsWDidTowdOxYulwt79+4115Mu5eehhx7Ccccdh5/+9KfYs2cPLrjgAiiKYq4nTexFFOPxrHxaJC6PbVuSNpXkqP2E6dOnY8WKFQCANWvWYOLEiTa3qH9x4MABXHjhhbj++utx9tlnAwAOOeQQrFy5EgCwYsUKHHnkkZgyZQpWrVqFcDiMrq4ubN68mbQqEY899hgeffRRLF26FAcffDDuvPNOzJkzhzSxmSOOOALvvPMOGGPYt28fgsEgjjnmGNLFRmpqakzjVVtbC1VV6feLIwrRYvr06Vi+fLm57RFHHFGSNgmMMVaSI/cDYqNEN27cCMYYbr/9dowbN87uZvUbbrvtNixbtgxjx441l/3iF7/AbbfdBkVRMHbsWNx2222QJAlPP/00nnrqKTDGcMkll2DevHk2trx/sHDhQtxyyy0QRRE33XQTaWIzv/3tb7Fy5UowxnDNNddg+PDhpIuNBAIB3HDDDWhuboaiKDj//PNx2GGHkSY2snPnTlx77bV4+umnsXXrVstaBINBLFq0CM3NzXA4HLj77rvR1NRU9PaRYSMIgiAIguAc6hIlCIIgCILgHDJsBEEQBEEQnEOGjSAIgiAIgnPIsBEEQRAEQXAOGTaCIAiCIAjOIcNGEAT3LFy4EAcddFDWfw8++KCl49x3332YNm1aiVsLnHjiifjVr35V8H7d3d2YN28etm3blndbxhjOOeccs1YUQRB9GyrLTxBERTB9+nQsWrQo47ohQ4ZYOsY555yDuXPnFrNZRWXJkiU47rjjMHr06LzbCoKA66+/HjfeeCNeeOEFuN3u0jeQIAjbIMNGEERFUFNTg6lTp/bqGIMHD8bgwYOL06Ais2PHDjz55JN4/fXXLe8zY8YM1NbW4sknn8QPfvCD0jWOIAjboS5RgiD6BM899xymTZuGd999F6eccgqmTp2K//7v/8b69evNbVK7RD/99FN8//vfx7Rp0zBjxgxcddVV2LVrl7leURQ8+OCDmDdvHiZPnowzzjgD//rXv5LO29zcjKuuugpHHHEEZs+ejX/+859pbevu7satt96KY489FlOmTMHChQvxxRdfJG3z8MMPY8qUKUnRwnztA4DTTjsNjzzyCFRV7dH7RhBEZUCGjSCIioAxBlVVM/6LEYlEcN1112HBggVYsmQJQqEQzj//fLS0tKQdLxgM4uKLL8agQYNw//3349Zbb8UXX3yBa6+91txm0aJFuP/++3Huuefij3/8I6ZNm4brrrsOzzzzDABA0zT88Ic/xOeff45bb70Vixcvxr333ot9+/Yltfuyyy7DSy+9hKuvvhr33HMPnE4nFi5ciK+//trc5uWXX8bJJ59cUPsA4OSTT8auXbuwZs2aorzP/3979xfSVB/HcfytqaW07TgrKqHEiqC1JZitk0YUQX8GXqyL/kA3QRExiKAkLwoWmIErrBAJiiUk0U1BsYigv5QuKIvuwkroootoY20TqaQ9F+F53KOZ0APP5vN5weC3nd/vnC+/q+/O9/c7R0Ryk0qiIpIXHj16hMvlGvfY69evARgeHubgwYPs3LkTgJqaGjZs2MDVq1cJBAJZY/r7+0kkEuzevdu661ZeXk40GuXHjx/09/cTiUQIBoPs2LEDgIaGBtLpNGfOnMHv9/Pw4UPevHnDtWvXrHJtVVUVfr/fus6TJ0+IRqOEw2HWrFkDwNq1a/H5fHR2dtLa2srbt2+JxWIsW7Zs0vEVFv78v11ZWYlhGESjUVauXPlHcywiuUsJm4jkhdraWpqbm8c9VlJSYrV9Pp/Vdjqd1NTU8Pz58zFjqqurMQyD/fv34/P5WLduHaZpsmrVKgBrzObNm7PGbd26lUgkwrt37+jr68PhcGStrXO5XFRWVlrfnz17RmlpKXV1dVl3AxsaGrh//z6AVeYcXQ79XXyjzZ8/f0ypVESmFiVsIpIXbDYbbrd7wj7Tp0/Hbrdn/eZ0OhkYGBjTd+bMmVy5coWOjg5u3LhBd3c3drudQ4cOsWvXLr58+UJRURGGYWSNmzVrFgDpdJpkMkl5efmYc8+ePdtqJxIJhoaGWL58+Zh+xcXFAKRSKYCsnZ6/i2+0GTNmkE6nJ5oaEclzSthEZMr4+vUrQ0NDlJaWWr/FYjGcTue4/ZcsWUJ7ezvfvn3jxYsXdHV1EQwGcblcOBwOhoeHSSQSWUnb58+fATAMA8Mwxl0fl0gkrLbNZqOiooILFy78Mu6R86dSqaxkb6L4VqxYYfVLJpMsXrx4wrkRkfymTQciMqU8ePDAasdiMV69eoXX6x3T7/Hjx5imSTwep6SkBNM0OXbsGAAfP36ktrYWgDt37mSNu337NhUVFVRVVeH1ekmlUvT29lrHBwYGrM0E8LOUG4/HKSsrw+12W59bt25x8+ZN4O9S6OjNCr+Lb0Qmk+HTp0+TfhadiOQn3WETkbyQTCZ/uRPSZrNZ7RMnTjA4OIjT6aSjowOHw2FtQhjN4/GQyWQIBALs3buX4uJiurq6sNvteL1enE4nmzZt4tSpUwwODrJ06VLu3btHJBLh+PHjFBYWUl9fT11dHUeOHOHw4cOUlZXR3t5ulToB1q9fj9vtZt++fQQCAebNm8fdu3fp7u4mGAwCsGjRIubMmcPLly8xTXNS8Y14//49yWSS+vr6f2OaRSRHKWETkbzQ19fH9u3bxz1mmiaNjY0AHD16lPPnzxOPx1m9ejXnzp3LSuhGGIbBxYsXOX36NE1NTXz//h2Px0M4HLZKqKFQiLNnz3L58mUSiQTV1dW0tbVZ1yooKKCzs5OTJ0/S0tJCUVERe/bsyXr47bRp07h06RKhUIi2tjbS6TQLFy6ktbXV2k1aUFDAxo0befr0KQcOHJh0fPBzF+rcuXPxeDz/wiyLSK4qyGQymf86CBGRP3X9+nWam5vp7e395Zq1XPbhwwe2bNlCJBKZ1KupRjQ2NuL3+/WmA5EpTmvYRERywIIFC9i2bRvhcHjSY3p6ekin09Zz4kRk6lLCJiKSI5qamujp6Rn3MST/lMlkCIVCtLS06MXvIv8DKomKiIiI5DjdYRMRERHJcUrYRERERHKcEjYRERGRHKeETURERCTHKWETERERyXF/AXTdc5S8hI8sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 7))\n",
    "ax1.set_xlabel('Episode(s)', fontsize=16) \n",
    "ax1.set_ylabel('Averaged Accumulated Rewards', fontsize=16) \n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(x = t2, y = average_accumulated_rewards, color=orange, alpha=0.3)\n",
    "sns.lineplot(x = t, y = averaged, color=orange, linewidth=2)\n",
    "plt.grid(color = 'white', linestyle = '--', linewidth = 1)\n",
    "plt.show()\n",
    "#sns.move_legend(ax, loc='upper left', frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20341c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe0f664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START state: (0, 0, 8, 0)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 7, 0)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 8, 0)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 8, 0)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 7, 0)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 7, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 7, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 7, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 5, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 4, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 2, 3)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 4)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 5)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 5)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 6)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 7)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "episode: 0/10, steps: 50, e: 1.0\n",
      "START state: (0, 0, 8, 1)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 8, 0)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 7, 0)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 7, 0)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 7, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 7, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 5, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 5, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 4, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 3)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 4)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 5)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 6)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 7)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 2, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "episode: 1/10, steps: 50, e: 1.0\n",
      "START state: (0, 0, 8, 1)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 9, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 9, 2)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 9, 2)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 9, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 8, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 7, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 5, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 4, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 3)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 4)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 5)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 6)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 7)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 2, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "episode: 2/10, steps: 50, e: 1.0\n",
      "START state: (0, 0, 8, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 8, 2)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 8, 3)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 8, 2)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 9, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 8, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 7, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 5, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 4, 2)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 4, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 3)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 4)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 4)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 5)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 6)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 7)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 1, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "episode: 3/10, steps: 50, e: 1.0\n",
      "START state: (0, 0, 8, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 8, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 7, 2)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 7, 3)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 7, 4)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 4)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 4)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 4)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 4)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 4)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 5)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 5)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 7, 5)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 7, 6)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 6)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 5, 6)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 4, 6)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 6)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 2, 6)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 7)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "episode: 4/10, steps: 50, e: 1.0\n",
      "START state: (0, 0, 9, 0)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 9, 0)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 8, 0)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 8, 1)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 9, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 9, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 8, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 7, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 5, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 4, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 2)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 3)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 4)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 5)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 6)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 7)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 7)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 2, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "episode: 5/10, steps: 50, e: 1.0\n",
      "START state: (0, 0, 9, 1)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 9, 1)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 9, 0)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 9, 0)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 9, 0)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 9, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 9, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 8, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 8, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 7, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 5, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 4, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 3)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 4)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 5)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 6)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 7)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 2, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "episode: 6/10, steps: 50, e: 1.0\n",
      "START state: (0, 0, 8, 0)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 9, 0)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 9, 0)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 8, 0)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 8, 0)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 8, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 8, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 7, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 1)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 6, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 5, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 4, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 2)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 3)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 4)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 5)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 6)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 7)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 7)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 2, 7)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 1, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "episode: 7/10, steps: 50, e: 1.0\n",
      "START state: (0, 0, 8, 0)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 8, 0)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 7, 0)\n",
      "action: 1\n",
      "reward0.0\n",
      "state: (0, 0, 8, 0)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 7, 0)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 7, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 7, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 5, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 4, 2)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 5, 2)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 5, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 4, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 3)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 4)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 5)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 6)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 7)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 2, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "episode: 8/10, steps: 50, e: 1.0\n",
      "START state: (0, 0, 9, 0)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 9, 0)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 8, 0)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 7, 0)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 0)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 6, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 6, 1)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 6, 2)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 6, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 5, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 4, 3)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 3)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 4)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 5)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 6)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 7)\n",
      "action: 2\n",
      "reward0.0\n",
      "state: (0, 0, 3, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 3, 7)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 2, 7)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 1, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward0.0\n",
      "state: (0, 0, 1, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 3\n",
      "reward0.0\n",
      "state: (0, 0, 0, 7)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 2\n",
      "reward10.0\n",
      "state: (0, 0, 0, 9)\n",
      "action: 3\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 1\n",
      "reward10.0\n",
      "state: (0, 0, 1, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "action: 0\n",
      "reward10.0\n",
      "state: (0, 0, 0, 8)\n",
      "episode: 9/10, steps: 50, e: 1.0\n"
     ]
    }
   ],
   "source": [
    "Path = csrl.verify_DRQN(EPISODES=10, num_steps=50, state_sequence_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bae3feda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The steps taken: 16\n",
      "path[80, 70, 70, 71, 72, 62, 52, 53, 43, 33, 34, 35, 36, 37, 38, 28, 18]\n"
     ]
    }
   ],
   "source": [
    "############################# Plot the Path ##############################\n",
    "import pylab as pl\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "path_idx = 1\n",
    "\n",
    "size_x = csrl.shape[2]\n",
    "size_y = csrl.shape[3]\n",
    "\n",
    "path=[]\n",
    "for i in range(len(Path[path_idx])):\n",
    "    if Path[path_idx][i] in [8,9,18,19]:\n",
    "        path.append(int(Path[path_idx][i]))\n",
    "        break\n",
    "    else:\n",
    "        path.append(int(Path[path_idx][i]))\n",
    "print('The steps taken: '+str(i))\n",
    "print('path'+str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a1819cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### q_0 ######\n",
    "    \n",
    "x = np.linspace(0,size_x,size_x+1)\n",
    "y = np.linspace(0,size_y,size_y+1) \n",
    "\n",
    "pl.figure(figsize=(10,10))\n",
    "\n",
    "hlines = np.column_stack(np.broadcast_arrays(x[0], y, x[-1], y))\n",
    "vlines = np.column_stack(np.broadcast_arrays(x, y[0], x, y[-1]))\n",
    "lines = np.concatenate([hlines, vlines]).reshape(-1, 2, 2)\n",
    "line_collection = LineCollection(lines, color=\"black\", linewidths=1)\n",
    "ax = pl.gca()\n",
    "ax.add_collection(line_collection)\n",
    "ax.set_xlim(int(x[0]), int(x[-1]))\n",
    "ax.set_ylim(int(y[0]), int(y[-1]))\n",
    "# backgroud color\n",
    "ax.add_patch(pl.Rectangle((0, 0), size_x, size_y, fill=True, color='green', alpha=.1))\n",
    "\n",
    "# plot the 'a' state 'q_0'\n",
    "b_start_x, b_start_y = 0,0\n",
    "b_size_x, b_size_y = 2,2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='blue', alpha=.5))\n",
    "# plot the 'b' state 'q_0'\n",
    "b_start_x, b_start_y = 8,8\n",
    "b_size_x, b_size_y = 2,2\n",
    "ax.add_patch(pl.Rectangle((b_start_x, b_start_y), b_size_x, b_size_y, fill=True, color='green', alpha=.5))\n",
    "\n",
    "# plot the BLOCK state 'q_0'\n",
    "start_x_1, start_y_1 = 4,8\n",
    "start_x_2, start_y_2 = 4,0\n",
    "start_x_3, start_y_3 = 0,4\n",
    "start_x_4, start_y_4 = 8,4\n",
    "start_x_5, start_y_5 = 4,4\n",
    "b_size_x, b_size_y = 2,2\n",
    "ax.add_patch(pl.Rectangle((start_x_1, start_y_1), b_size_x, b_size_y, fill=True, color='black', alpha=.5))\n",
    "ax.add_patch(pl.Rectangle((start_x_2, start_y_2), b_size_x, b_size_y, fill=True, color='black', alpha=.5))\n",
    "ax.add_patch(pl.Rectangle((start_x_3, start_y_3), b_size_x, b_size_y, fill=True, color='black', alpha=.5))\n",
    "ax.add_patch(pl.Rectangle((start_x_4, start_y_4), b_size_x, b_size_y, fill=True, color='black', alpha=.5))\n",
    "ax.add_patch(pl.Rectangle((start_x_5, start_y_5), b_size_x, b_size_y, fill=True, color='black', alpha=.5))\n",
    "\n",
    "for i in range(len(path)):\n",
    "    state_idx = path[i]+1\n",
    "    ## convert state index in Julia to 'x,y' coordinates in python\n",
    "    if state_idx%size_x==0:\n",
    "        coord_x = size_x-1    # x_coordinate\n",
    "        #coord_y = int(size_y - (state_idx-state_idx%size_x)/size_x) # y_coordinate\n",
    "        coord_y = int(size_y - (state_idx/size_y)) # y_coordinate\n",
    "    else:\n",
    "        coord_x = state_idx%size_x-1    # x_coordinate\n",
    "        coord_y = int(size_y - 1 - (state_idx-state_idx%size_x)/size_x) # y_coordinate\n",
    "    ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.2, fill=True, color='red', alpha=.4))\n",
    "    if i==0:\n",
    "        # start point\n",
    "        #ax.add_patch(pl.Circle((coord_x+0.5, coord_y+0.5), 0.4, fill=True, color='purple', alpha=.9))\n",
    "        ax.add_patch(pl.Circle((1+0.5, 1+0.5), 0.4, fill=True, color='purple', alpha=.9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa7192c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5b961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3736ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
